<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-TW">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222">












<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />






















<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.0.6" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.0.6">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.0.6">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.0.6">


  <link rel="mask-icon" href="/images/logo.svg?v=6.0.6" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '6.0.6',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta property="og:type" content="website">
<meta property="og:title" content="odie&#39;s whisper">
<meta property="og:url" content="https://odie2630463.github.io/index.html">
<meta property="og:site_name" content="odie&#39;s whisper">
<meta property="og:locale" content="zh-TW">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="odie&#39;s whisper">






  <link rel="canonical" href="https://odie2630463.github.io/"/>



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>odie's whisper</title>
  









  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-TW">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"> 

<div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">odie's whisper</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切換導航欄">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        
          
  <li class="menu-item menu-item-home">
    <a href="/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-home"></i> <br />首頁</a>
</li>

      
        
        
          
  <li class="menu-item menu-item-about">
    <a href="/about/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-user"></i> <br />關於</a>
</li>

      
        
        
          
  <li class="menu-item menu-item-tags">
    <a href="/tags/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />標籤</a>
</li>

      
        
        
          
  <li class="menu-item menu-item-categories">
    <a href="/categories/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-th"></i> <br />分類</a>
</li>

      
        
        
          
  <li class="menu-item menu-item-archives">
    <a href="/archives/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />歸檔</a>
</li>

      

      
    </ul>
  

  
    

    
    
      
      
    
      
      
    
      
      
    
      
      
    
      
      
    
    

  


  

  
</nav>


  



 </div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://odie2630463.github.io/2020/02/27/stacked-capsule-net/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="odie">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="odie's whisper">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/02/27/stacked-capsule-net/" itemprop="url">Stacked Capsule Autoencoders</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">發表於</span>
              
              <time title="創建於" itemprop="dateCreated datePublished" datetime="2020-02-27T11:16:04+08:00">2020-02-27</time>
            

            
            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分類於</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/paper/" itemprop="url" rel="index"><span itemprop="name">paper</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Hinton 大神於2017年提出 <a href="http://papers.nips.cc/paper/6975-dynamic-routing-between-capsules" target="_blank" rel="noopener"><em>Dynamic Routing Between Capsules</em></a>，探討了CNN的缺陷並提出Capsules概念，2018的 <a href="https://openreview.net/forum?id=HJWLfGWRb" target="_blank" rel="noopener"><em>Matrix capsules with EM routing</em></a> 改進了其中 routing 機制，到2019年這篇 <a href="https://arxiv.org/abs/1906.06818" target="_blank" rel="noopener"><em>Stacked Capsule Autoencoders</em></a> 算是這個系列的集大成，概念脈絡更為清楚，大神也在 AAAI 2020 給了一個關於本篇論文的<a href="https://youtu.be/UX8OubxsY8w" target="_blank" rel="noopener">演講</a>，他還特別提到說請大家忘記前兩篇論文，這篇才是對的！足見這一篇論文的重要性</p>
<p>本篇文章不是詳細解讀 <em>Stacked Capsule Autoencoders (SCAE)</em>的文章，如果想要深入了解這篇論文，推薦看第一作者寫的<a href="http://akosiorek.github.io/ml/2019/06/23/stacked_capsule_autoencoders.html" target="_blank" rel="noopener">部落格文章</a>與搭配論文服用，本篇文章是想從生成模型的角度去重新理解與實作 capsule 這個概念，建議先閱讀過<a href="https://odie2630463.github.io/2020/01/13/un-obj-detection/">之前的文章</a>，用生成模型概念來解決物件偵測問題跟本論文也有很相似的概念，另外很有趣的是，上述提到第一作者的部落格文章中，有提到<strong>為何不用生成模型的方式來實現 SCAE</strong>，這也啟發我一些思考與後續探討，故寫成文章與大家討論</p>
<h2 id="Stacked-Capsule-Autoencoders"><a href="#Stacked-Capsule-Autoencoders" class="headerlink" title="Stacked Capsule Autoencoders"></a>Stacked Capsule Autoencoders</h2><p><img src="/media/15826453668789.jpg" alt="-w628"></p>
<h3 id="Capsules"><a href="#Capsules" class="headerlink" title="Capsules"></a>Capsules</h3><p>在進入模型架構前，想先來談談 capsule 這個概念，上述提到的作者部落格文章中有定義什麼是 capsule</p>
<blockquote>
<p>We define a capsule as a specialized part of a model that describes an abstract entity, e.g. a part or an object.</p>
</blockquote>
<p>形象上的描述就是<strong>積木與組合</strong>，一個高階概念是由多個低階概念所組成，低階的概念就像是積木一樣，我們可以組合出更複雜的物件，也就是高階概念，組合的過程中，我們要去選取適當的積木，還要去旋轉積木的姿態來組合；從視覺辨識物件的過程來看，我們看到一個影像並想要知道那是什麼，先去辨識影像用了哪些積木，那些積木分別姿態是什麼，這比起直接去辨識整個物件，積木多半更為簡單，更容易辨識出來，然後我們將有用到的積木搜集起來，看看用這些積木能組合出什麼，透過訓練我們希望特定積木的集合，會對應到特定的物件類別，看到收集到的積木就知道這大概只能組合出哪些東西，我們就能知道這個影像是什麼，這樣組合過程可以一直下去，從只有幾個積木，但到最後可以組合出非常複雜的影像或概念</p>
<p><img src="/media/15827059978437.jpg" alt="-w723"></p>
<p>概覽一下整個模型，輸入影像後找出使用的積木與姿態，再來根據收集到的積木來看能組合出哪些物件</p>
<h3 id="Part-Capsule-Autoencoder"><a href="#Part-Capsule-Autoencoder" class="headerlink" title="Part Capsule Autoencoder"></a>Part Capsule Autoencoder</h3><p><img src="/media/15827065660727.jpg" alt="-w823"></p>
<p>第一部分訓練模型去學習積木與估計姿態，姿態包含位置、大小、旋轉，積木是指有多個小張影像，例如輸入影像是28x28，積木影像為11x11，輸入影像後模型會輸出每個積木影像的使用機率與姿態，然後還原輸入影像來訓練模型與積木影像</p>
<h3 id="Object-Capsule-Autoencoder"><a href="#Object-Capsule-Autoencoder" class="headerlink" title="Object Capsule Autoencoder"></a>Object Capsule Autoencoder</h3><p><img src="/media/15827065812926.jpg" alt="-w628"></p>
<p>第二部分為把積木聚合成物件，使用 EM 的迭代估計的方式(類似 Kmean)，來找出中心點，且加入 sparsity regularization 讓積木只集中在某幾個物件上</p>
<h2 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h2><p>接著我們來嘗試實作 Part Capsule Autoencoder，這個部分與之前實作<a href="https://odie2630463.github.io/2020/01/13/un-obj-detection/">非監督的物件偵測</a>概念非常類似，也同樣使用 Pyro 來實作，生成模型必須使用積木去組合出影像，積木的使用機率與姿態就是隱藏變量，我們訓練另一個模型去估計這些變量</p>
<p><a href="https://colab.research.google.com/drive/1KS0HdxNWj0RplDimwqHfYx7M3qgSScw3" target="_blank" rel="noopener">我的實作於Colab</a></p>
<h3 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(self,obs)</span>:</span></span><br><span class="line">        templates = pyro.param(<span class="string">'templates'</span>,self.templates)</span><br><span class="line">    </span><br><span class="line">        B = pyro.plate(<span class="string">'B'</span>,size=self.batch_size,dim=<span class="number">-3</span>)</span><br><span class="line">        N = pyro.plate(<span class="string">'N'</span>,size=self.n_templates,dim=<span class="number">-2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> B,N:</span><br><span class="line">            part_view = pyro.sample(<span class="string">'part_view'</span>,dist.Normal(self.part_view_prior_mu,</span><br><span class="line">                                                            self.part_view_prior_scale))</span><br><span class="line">            part_logit = pyro.sample(<span class="string">'part_logit'</span>,dist.Normal(self.part_logit_prior_mu,</span><br><span class="line">                                                            self.part_logit_prior_scale))</span><br><span class="line">  </span><br><span class="line">        layers , imgs_ = self.render(part_view , part_logit)</span><br><span class="line">        imgs = pyro.sample(<span class="string">'images'</span>,dist.Normal(imgs_ , <span class="number">0.01</span>*torch.ones_like(imgs_)).to_event(<span class="number">2</span>) , obs=obs)</span><br><span class="line">        <span class="keyword">return</span> layers , imgs</span><br></pre></td></tr></table></figure>

<p>大致看一下生成模型定義，詳細的函數可以參考我的實作，templates 就是積木，這裡用了16個11x11的影像，並且也是可以學習的，接著每個 templates 都去抽樣出姿態與使用機率，最後用可微分渲染器去生成影像，我們直接生成影像來看看</p>
<p><img src="/media/init_sample.png" alt="init_sample"></p>
<h3 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h3><p>模型在 MNIST 訓練資料集上訓練，得到一些不錯的結果，下圖左邊是訓練資料，右邊是還原影像</p>
<p><img src="/media/15827324081106.jpg" alt=""></p>
<p>我們來看看模型學到的積木長怎樣，左邊是論文給出的模型訓練在 MNIST 學到的結果，右邊則是實作得到的，雖然與論文設定不完全相同，但顯示模型有學到一些有用的積木</p>
<p><img src="/media/15827326690735.jpg" alt=""></p>
<p>右邊是依照使用機率排序的 templates，左邊是將使用機率高於0.5的積木來組合成影像，顯示模型是會去選擇重要的積木來組成，不是全部都用上</p>
<p><img src="/media/15827329342409.jpg" alt=""></p>
<p>在測試資料集上，也有不錯的效果，右邊是測試資料，左邊是還原影像</p>
<p><img src="/media/15827334224668.jpg" alt=""></p>
<p>選取機率高的積木來組成</p>
<p><img src="/media/15827335436074.jpg" alt=""></p>
<h2 id="結語"><a href="#結語" class="headerlink" title="結語"></a>結語</h2><p>我的實作版本與<a href="https://github.com/google-research/google-research/tree/master/stacked_capsule_autoencoders" target="_blank" rel="noopener">官方實作</a>是不同的，雖然 capsules 概念上是相同的，不同點在於 SCAE 官方實作把 capsules 概念放到估計模型上，而我的版本則放到生成模型裡</p>
<ul>
<li>官方實作：capsules encoder + decoder</li>
<li>我的實作：encoder + capsules generator</li>
</ul>
<p>作者認為 SCAE 當然可以用生成模型來實作，像是我們很熟悉的VI框架一樣，定義一個生成模型與估計模型，用估計模型去近似隱藏變量，但我們往往都是把一些結構先驗知識放到生成模型去，我們會去假設變量之間關係與結構等等，再用任意的模型去當估計模型，但這樣的缺點就是隱變量後驗分佈往往很複雜，估計模型不容易很好近似，估計模型應該需要更多的額外知識來輔助，如果估計模型裡沒有 capsules 架構是無法學到 capsule-like representations 的</p>
<p>我的版本則是照生成模型的概念去實現，如果解碼器太過強大，它是可以忽略編碼器給的訊息，依然可以把資料還原得很好，所以就算編碼器是含有有先驗結構的，也可能無法學到有用資訊，所以我將先驗結構放在生成模型，用估計模型來近似，希望可以得到近似 capsule-like representations 的結果</p>
<p>另外提一個不太嚴謹的想法，我認為人在辨識物件大部分時間都是依賴快速、自動化，接近反射的過程，這是後你用上的是估計模型，是一種快速近似；當你便是不出是什麼物體時候，你會停下來思考，甚至轉動你的視角，嘗試去精確估計，這時候你不會使用估計模型，而是專為你眼前的物體重新去估計變量，經過一些思考計算，你可以精確估計出來積木與姿態等等，並也可以在腦海中還原出這個物體，再把估計到的這些變量丟給估計模型去重新訓練，這裡用的就是監督式學習，估計模型看到這樣的物體就應該要估計出怎樣的變量數值，所以兩種快慢的認知模式，是同時存在與交互訓練的</p>
<p>敬啟期待！</p>
<h2 id="Refernece"><a href="#Refernece" class="headerlink" title="Refernece"></a>Refernece</h2><ul>
<li><a href="http://akosiorek.github.io/ml/2019/06/23/stacked_capsule_autoencoders.html" target="_blank" rel="noopener">第一作者的部落格文章</a></li>
<li><a href="https://arxiv.org/pdf/1906.06818.pdf" target="_blank" rel="noopener">Stacked Capsule Autoencoders</a></li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://odie2630463.github.io/2020/01/13/un-obj-detection/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="odie">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="odie's whisper">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2020/01/13/un-obj-detection/" itemprop="url">Unsupervised object detection with pyro</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">發表於</span>
              
              <time title="創建於" itemprop="dateCreated datePublished" datetime="2020-01-13T17:04:26+08:00">2020-01-13</time>
            

            
            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分類於</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/probabilistic-programming/" itemprop="url" rel="index"><span itemprop="name">probabilistic programming</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>我們是如何理解由視覺接受到的場景與畫面呢？因為雙眼立體視覺的關係，我們能輕易透過深度感知，來區分遠近背景與物件，個別物件再去理解其位置、描述，甚至是物件之間的關係，我們對於場景的理解是「物件導向」的，我們先有了各種物件的概念，再去感知它們出現在哪？它們有怎樣的描述？它們有什麼關係？腦袋如何生成一幅「心智圖畫」來反應世界？</p>
<p>我們觀測到現實，並且對於其中一些隱藏變量進行估計，例如物件數量、位置、描述等等，然後在腦海中重新生成一幅「心智圖畫」來代表所看到的現實，如果所估計的變量正確，我們期待所生成的心智圖畫會跟現實很像；本篇我們使用 Pyro 來實作一個生成模型，模型生成個別物件的資訊與位置，然後透過可微分渲染器來產生影像，最後使用VI老方法來訓練生成模型與估計模型。</p>
<p>本篇主要參考了 Refernece 中的第一篇，為 AAAI 2019 的論文，簡化了模型與實驗的設定，並且用 Pyro 機率語言更簡明的實作出來（原始論文的code是tf 1.x寫的，很難讀呀…）</p>
<p><a href="https://colab.research.google.com/drive/1UVX-RNf_FyZF0kwueQmCrCVCKX9WUemP" target="_blank" rel="noopener">我的實作於Colab</a></p>
<h2 id="可微分渲染器"><a href="#可微分渲染器" class="headerlink" title="可微分渲染器"></a>可微分渲染器</h2><p>假設我們有個物件要擺到畫布上，我們可以透過 Indexing，例如array[i,j] = obj，但 Pytorch indexing 是無法傳遞梯度的，例子中的 i,j 是無法微分的，所以我們沒辦法去有梯度改變i,j，把物件移動到我們想要的地方，這可是大問題呀！沒有可微分的渲染器，就沒辦法生成影像，所以可微分程式是很重要的呀！（關於可微分程式之後再跟大家分享討論）</p>
<p>我們希望擺的位置是可以<strong>微分</strong>的，該怎麼做呢？我們可以用 Spatial transformer networks (STN) 來將物件放到畫布上，並且整個過程是可以微分的，但這裡不詳述STN的原理</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">render</span><span class="params">(obj_param,logit)</span>:</span></span><br><span class="line">  img_param = obj_to_image_param(obj_param)</span><br><span class="line">  img_param = img_param.view(<span class="number">-1</span>,<span class="number">2</span>)</span><br><span class="line">  bs = img_param.size(<span class="number">0</span>)</span><br><span class="line">  </span><br><span class="line">  logit = (logit_scale*logit.view(<span class="number">-1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>)).sigmoid()</span><br><span class="line">  obj = torch.ones((bs,<span class="number">1</span>,obj_size,obj_size))*logit</span><br><span class="line">  </span><br><span class="line">  theta = torch.zeros(bs,<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line">  theta[:,<span class="number">0</span>,<span class="number">0</span>] = ratio</span><br><span class="line">  theta[:,<span class="number">1</span>,<span class="number">1</span>] = ratio</span><br><span class="line">  theta[:,:,<span class="number">-1</span>] = img_param</span><br><span class="line">  </span><br><span class="line">  grid = affine_grid(theta, torch.Size((bs,<span class="number">1</span>,img_size,img_size)))</span><br><span class="line">  out = grid_sample(obj, grid)</span><br><span class="line">  out = out.view(batch_size,<span class="number">-1</span>,<span class="number">1</span>,img_size,img_size)</span><br><span class="line">  <span class="keyword">return</span> out , out.sum(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>obj_param 代表物件的座標參數，logit 代表物件出現的機率，透過 obj_to_image_param 做參數的轉換，把物件參數轉換到畫布參數，並放到 theta 中用 affine_grid 與 grid_sample 函數來把物件放到畫布上</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">out , img_ = render(torch.zeros(<span class="number">2</span>,<span class="number">4</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">2</span>),torch.ones(<span class="number">2</span>,<span class="number">4</span>,<span class="number">4</span>,<span class="number">2</span>,<span class="number">1</span>))</span><br></pre></td></tr></table></figure>

<p>借鏡 Yolo 模型，把影像分成4*4的方格，每個方格內可以有2個物件，每個物件有x,y偏移座標與出現機率，測試一下渲染器，每個方格內有2個白色物件，且偏移座標為0（所以在正中間重疊），出現機率都是1</p>
<p><img src="/media/grid.png" alt="grid"></p>
<h2 id="Yolo-like-generative-model"><a href="#Yolo-like-generative-model" class="headerlink" title="Yolo-like generative model"></a>Yolo-like generative model</h2><p>模型根據定義的維度，每個物件可能出現的方格內抽樣物件的座標與機率，用Pyro來表示相當簡潔，plate代表每個維度間互相獨立，抽樣出來的參數在送給宣染器來產生抽樣出影像</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(obs)</span>:</span></span><br><span class="line">  B = pyro.plate(<span class="string">'B'</span>,size=<span class="number">2</span>,dim=<span class="number">-5</span>)</span><br><span class="line">  H = pyro.plate(<span class="string">'H'</span>,size=<span class="number">4</span>,dim=<span class="number">-4</span>)</span><br><span class="line">  W = pyro.plate(<span class="string">'W'</span>,size=<span class="number">4</span>,dim=<span class="number">-3</span>)</span><br><span class="line">  N = pyro.plate(<span class="string">'N'</span>,size=<span class="number">2</span>,dim=<span class="number">-2</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">with</span> B,H,W,N:</span><br><span class="line">    pos = pyro.sample(<span class="string">'obj_param'</span>,dist.Normal(torch.zeros(<span class="number">2</span>),torch.ones(<span class="number">2</span>)))</span><br><span class="line">    logit = pyro.sample(<span class="string">'obj_logit'</span>,dist.Normal(torch.tensor(<span class="number">-1.</span>),torch.ones(<span class="number">1</span>)))</span><br><span class="line">    </span><br><span class="line">  out , imgs_ = render(pos,logit)</span><br><span class="line">  imgs = pyro.sample(<span class="string">'images'</span>,</span><br><span class="line">                     dist.Normal(imgs_ , <span class="number">0.01</span>*torch.ones_like(imgs_)).to_event(<span class="number">2</span>) , obs=obs)</span><br><span class="line">  <span class="keyword">return</span> out , imgs</span><br></pre></td></tr></table></figure>

<p>從模型直接做抽樣，物件的深淺反映可能出現的機率</p>
<p><img src="/media/sample1.png" alt="sample1"><br><img src="/media/sample2.png" alt="sample2"></p>
<h2 id="Guide"><a href="#Guide" class="headerlink" title="Guide"></a>Guide</h2><p>接著來做估計，可以先嘗試看看點估計，看看VI方法能不能估計出想要的隱藏變量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">guide = AutoDelta(pyro.poutine.block(model, expose=[<span class="string">"obj_param"</span>,<span class="string">"obj_logit"</span>]))</span><br></pre></td></tr></table></figure>

<p>或是用Amortized inference，引入一個估計模型訓練神經網路直接去預測隱藏變量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">encoder = nn.Sequential(nn.Conv2d(<span class="number">1</span>,<span class="number">16</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>),</span><br><span class="line">                        nn.ReLU(),</span><br><span class="line">                        nn.Conv2d(<span class="number">16</span>,<span class="number">32</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>),</span><br><span class="line">                        nn.ReLU(),</span><br><span class="line">                        nn.Conv2d(<span class="number">32</span>,<span class="number">32</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>),</span><br><span class="line">                        nn.ReLU(),</span><br><span class="line">                        nn.Conv2d(<span class="number">32</span>,<span class="number">16</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>),</span><br><span class="line">                        nn.ReLU(),</span><br><span class="line">                        nn.Conv2d(<span class="number">16</span>,<span class="number">6</span>,<span class="number">1</span>,<span class="number">1</span>))</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">guide</span><span class="params">(imgs)</span>:</span></span><br><span class="line">  pyro.module(<span class="string">"encoder"</span>, encoder)</span><br><span class="line">  feats = encoder(imgs).permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>).view(batch_size,H,W,C,<span class="number">3</span>).contiguous()</span><br><span class="line">  s1 = pyro.sample(<span class="string">'obj_logit'</span>,dist.Delta(feats[:,:,:,:,:<span class="number">1</span>]))</span><br><span class="line">  s2 = pyro.sample(<span class="string">'obj_param'</span>,dist.Delta(feats[:,:,:,:,<span class="number">1</span>:]))</span><br></pre></td></tr></table></figure>

<h2 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h2><p>當 Model 與 Guide 都定義好後，就用VI方法來訓練囉！（比自己從頭寫，方便多了呀！）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">pyro.clear_param_store()</span><br><span class="line">elbo = Trace_ELBO()</span><br><span class="line">optim = pyro.optim.Adam(&#123;<span class="string">'lr'</span>: <span class="number">1e-3</span>&#125;)</span><br><span class="line">svi = SVI(model, guide, optim, loss=elbo)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">  loss = svi.step(imgs)</span><br><span class="line">print(loss)</span><br></pre></td></tr></table></figure>

<h2 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h2><p>把訓練過後的 guide 所估計的物件框畫在訓練資料上來看看，可以看到還蠻不錯的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">idx = <span class="number">0</span></span><br><span class="line">filter_img_param_ = get_bbox(obj_param_[idx],obj_logit_[idx],t=<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">5</span>, <span class="number">5</span>))</span><br><span class="line">plt.imshow(imgs[idx].view(img_size,img_size).detach().numpy(),cmap=<span class="string">'gray'</span>)</span><br><span class="line">currentAxis=plt.gca()</span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> filter_img_param_:</span><br><span class="line">  x,y = param_to_px(p)</span><br><span class="line">  rect=patches.Rectangle((x<span class="number">-5</span>, y<span class="number">-5</span>),obj_size,obj_size,linewidth=<span class="number">1</span>,edgecolor=<span class="string">'r'</span>,facecolor=<span class="string">'none'</span>)</span><br><span class="line">  currentAxis.add_patch(rect)</span><br></pre></td></tr></table></figure>

<p><img src="/media/sample3.png" alt="sample3"></p>
<p>目前我們是直接用模型來生成訓練資料，生成的資料完全符合模型假設，當然比較容易訓練，我們來換個生成訓練資料的方式，用均勻分布的方式抽樣物件數量與位置，還有把物件換成圓形</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">draw_sprites</span><span class="params">()</span>:</span></span><br><span class="line">  img = Image.new(<span class="string">'L'</span>, (<span class="number">64</span>, <span class="number">64</span>))</span><br><span class="line">  drawer = ImageDraw.Draw(img)</span><br><span class="line">  num_sprite = randint(<span class="number">1</span>,<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> range(num_sprite):</span><br><span class="line">    x = randint(<span class="number">0</span>,img_size - obj_size)</span><br><span class="line">    y = randint(<span class="number">0</span>,img_size - obj_size)</span><br><span class="line">    drawer.ellipse((x,y,x+obj_size,y+obj_size),fill=(<span class="number">255</span>))</span><br><span class="line">  <span class="keyword">return</span> img</span><br></pre></td></tr></table></figure>

<p><img src="/media/train2.png" alt="train2"><br><img src="/media/train2-2.png" alt="train2-2"></p>
<p>經過訓練後結果<br><img src="/media/test2-1.png" alt="test2-1"><br><img src="/media/test2-2.png" alt="test2-2"></p>
<h2 id="結語"><a href="#結語" class="headerlink" title="結語"></a>結語</h2><p>本篇介紹了一個 Unsupervised object detection 的方法，我們定義了一個影像生成的過程與模型，我們假設所看到的影像背後都有一些隱藏的<strong>生成參數</strong>，我們如果能很好的估計出來，就能也生成出接近一樣的影像（影像還原誤差），所以我們可以透過著個方式，來評斷估計的隱變量好壞，進而去訓練估計模型預測隱變量，物件座標也只是其中的一種隱變量，還有物件大小、類別、甚至光影都可以是，都可以套用這個框架去延伸，當然本篇只是淺嚐而止，只是一個概念驗證，離能真的用在真實影像上的物件偵測還非常的遠，但多少能換個思路去理解<strong>生成模型</strong>或是<strong>非監督式學習</strong>能怎樣扮演其他學習任務的基石。</p>
<p>下篇已經大概知道要寫什麼，但還沒寫之前都不敢說，敬請期待！</p>
<h2 id="Refernece"><a href="#Refernece" class="headerlink" title="Refernece"></a>Refernece</h2><ul>
<li><a href="http://e2crawfo.github.io/pdfs/spair_aaai_2019.pdf" target="_blank" rel="noopener">Spatially Invariant Unsupervised Object Detection with Convolutional Neural<br>Networks
</a></li>
<li><a href="https://arxiv.org/abs/1603.08575" target="_blank" rel="noopener">Attend, Infer, Repeat: Fast Scene Understanding with Generative Models</a></li>
<li><a href="https://pyro.ai/examples/air.html" target="_blank" rel="noopener">Attend Infer Repeat - Pyro</a></li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://odie2630463.github.io/2019/12/03/vi-3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="odie">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="odie's whisper">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/12/03/vi-3/" itemprop="url">漫談 Variational Inference (三)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">發表於</span>
              
              <time title="創建於" itemprop="dateCreated datePublished" datetime="2019-12-03T17:24:52+08:00">2019-12-03</time>
            

            
            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分類於</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/variational-inference/" itemprop="url" rel="index"><span itemprop="name">variational inference</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>沒想到一晃眼就是一年了，但自己挖的坑還是要填完，希望又能開始恢復寫部落格的習慣，也把自己關注的研究陸續整理上來，期待能獲得一些新想法，要訓練<strong>自己能用多個角度去看同一個問題，能把多個問題歸納成同一個框架</strong></p>
<p>本篇是漫談 Variational Inference 系列第三篇，<a href="https://odie2630463.github.io/2018/09/20/vi-2/">第二篇</a>介紹了VAE，把深度學習與VI做個結合，也引領出了很多後續的研究；而本篇來談談VI方法跟一些其他生成模型的關係，用一致的框架來討論VAE與GAN</p>
<h2 id="New-formulation-of-VAE"><a href="#New-formulation-of-VAE" class="headerlink" title="New formulation of VAE"></a>New formulation of VAE</h2><p>首先我們有 $q_{\phi}(x,z)=q_{\phi}(z|x)p(x)$ 與 $p_{\theta}(x,z)=p_{\theta}(x|z)p(z)$，那來對上一篇VAE的ELBO計算期望值</p>
<p>$<br>\begin{split}<br>E_x \left[<br>    E_{q_{\phi}(z|x)}<br>        \left[ \log \frac{p_{\theta}(x,z)}          {q_{\phi}(z|x)}\right]<br>        \right] &amp;= E_{q_{\phi}(x,z)}<br>        \left[ \log \frac{p_{\theta}(x,z)}          {q_{\phi}(z|x)}\right]  \\<br>          &amp;= E_{q_{\phi}(x,z)}<br>        \left[ \log \frac{p_{\theta}(x,z)}          {q_{\phi}(z|x)} + \log p(x) - \log p(x) \right] \\<br>        &amp;= E_{q_{\phi}(x,z)}<br>        \left[ \log \frac{p_{\theta}(x,z)}          {q_{\phi}(x,z)} + \log p(x) \right]  \\<br>        &amp;= KL(q_{\phi}(x,z) || p_{\theta}(x,z)) + C<br>\end{split}<br>$</p>
<p>做了一些變換後，可以把ELBO表示成兩個聯合機率分布的KL距離，我們關注的是 $p_{\theta}(x,z)$，希望可以生成很真實的樣本，KL是個非對稱的divergence，交換位置是完全不同的效果，生成器$p_{\theta}(x,z)$於計算KL的位置會影響優化的目標，這也導致了VAE生成樣本比較模糊，但不容易<strong>Mode collapse</strong>的原因，我們接著來看GAN的形式如何，再來一起討論其異同</p>
<h2 id="New-formulation-of-GAN"><a href="#New-formulation-of-GAN" class="headerlink" title="New formulation of GAN"></a>New formulation of GAN</h2><p>接著我們也是看看把GAN整理成類似的形式，方便後續的分析比較，$y$代表真實資料(y=1)或是生成樣本(y=0)，現在我們換個角度來看，<strong>把$x$當作隱變量而$y$視為可觀測的輸入</strong>，我們想用一個候選分佈$p_{\theta}(x|y)$，希望去優化$q_{\phi}(y|x)$這個條件機率(判別器)，GAN訓練過程我們會輸入真實資料與生成樣本給判別器去，我們現在的候選分佈應該是由$g_{\theta}(x)$生成與$p_{\text data}(x)$混合而成，所以把$p_{\theta}(x|y)$寫成：</p>
<!--
![](/media/15753671192197.jpg)
-->

<p>$$<br>p_{\theta}(x | y)=\left \{<br>\begin{array}{ll}<br>{p_{g_{\theta}}(x)} &amp; {y=0} \\<br>{p_{\text {data}}(x)} &amp; {y=1}<br>\end{array}\right.<br>$$</p>
<p>優化的目標也會依訓練過程不同，兩個階段是相反的，候選分佈會隨機給真實資料或是生成樣本，訓練$q_{\phi}(y|x)$判別器分類正確</p>
<p>$$<br>\max_{\boldsymbol{\phi}} L_{\phi} = \mathbb{E}_{p_{\theta}(\boldsymbol{x} | y)p(y)}\left[\log q_{\phi}(y | \boldsymbol{x})\right]<br>$$</p>
<p>於訓練$g_{\theta}(x)$生成器階段，我們希望$q_{\phi}(y|x)$分類錯誤，$q_{\phi}^r(y|x)$表示相反的$y$，優化目標變成</p>
<p>$$<br>\max_{\boldsymbol{\theta}} \mathcal{L}_{\theta}=\mathbb{E}_{p_{\theta}(\boldsymbol{x} | y) p(y)}\left[\log q_{\phi}^r(y | \boldsymbol{x})\right]<br>$$</p>
<p>跟VAE不同，兩個階段優化的目標並不一樣，這也導致訓練更為困難，我們對訓練生成器階段做個推導整理，並且加上負號來改成最小化</p>
<p>$<br>\begin{split}<br>E_{p(y)}\left[<br>    E_{p_{\theta}(x|y)}<br>        \left[ - \log q_{\phi}^r(y | x)\right]<br>        \right] &amp;= E_{p(y)p_{\theta}(x|y)}\left[ \log \frac{q_{\phi}^r(y | x)p_{\theta^\prime}(x)}{p_{\theta}(x|y)p(y)} - \log \frac{p_{\theta}(x|y)p(y)}{p_{\theta^\prime}(x)} \right] \\<br>        &amp;= KL(p_{\theta}(x,y) || q_{\phi}^r(x,y)) - KL(p_{\theta}(x,y) || p_{\theta^\prime}(x))<br>\end{split}<br>$</p>
<p>推導過程中我們加入$x$的先驗分佈$p_{\theta^\prime}(x)= \sum_y p_{\theta^\prime}(y|x)p(y)$，訓練生成器時候，我們會由上一輪訓練出來的$g_{\theta^\prime}$生成樣本與真實資料去訓練新的$g_{\theta}$，所以每次先驗分佈都在改變，最後我們得到一個跟VAE類似的結果，但是$p_{\theta}(x,y)$在KL中的位置是相反的</p>
<h2 id="Compare-VAE-and-GAN"><a href="#Compare-VAE-and-GAN" class="headerlink" title="Compare VAE and GAN"></a>Compare VAE and GAN</h2><h3 id="Mode-covering-and-collapse"><a href="#Mode-covering-and-collapse" class="headerlink" title="Mode covering and collapse"></a>Mode covering and collapse</h3><p>我們看到兩種模型的優化目標是相反的KL divergence，VAE傾向去<strong>覆蓋</strong>整個分佈，但也可能會覆蓋到一些機率密度低的位置，而使得有時候抽樣出來的影像不夠真實，所以VAE除了使用L2 loss去計算影像還原損失，本身就會導致模糊外，更深一層本質上是KL的特性所導致</p>
<p>GAN則為相反，傾向去學好一個Mode，認真顧好一個部分就好，所以能產生非常真實的資料，但會有Mode collapse</p>
<p><img src="/media/15753578381818.jpg" alt="-w824"></p>
<h3 id="Different-prior"><a href="#Different-prior" class="headerlink" title="Different prior"></a>Different prior</h3><p>推導過程中我們都有引入$x$的先驗分佈，</p>
<ul>
<li>VAE：$p(x)$代表的是真實資料分布</li>
<li>GAN：$p_{\theta^\prime}(x)$代表的是混和分佈</li>
</ul>
<h4 id="Mixed-prior"><a href="#Mixed-prior" class="headerlink" title="Mixed prior"></a>Mixed prior</h4><p>我們換從訓練判別器階段來分析，我們嘗試把$p_{\theta^\prime}(x)$當作先驗分佈引入在拆解$q_{\phi}(x,y)$時</p>
<p>$<br>\begin{split}<br>KL(p_{\theta}(x,y) || q_{\phi}(x,y))<br>&amp;= \int p_{data}(x) \log \frac{p_{data}(x)}{q_{\phi}(x,y=1)} + \int p_{g_{\theta}}(x) \log \frac{p_{g_{\theta}}(x)}{q_{\phi}(x,y=0)} \\<br>&amp;= \int p_{data}(x) \log \frac{p_{data}(x)}{q_{\phi}(y=1|x)p_{data}(x)} + \int p_{g_{\theta}}(x) \log \frac{p_{g_{\theta}}(x)}{q_{\phi}(y=0|x)p_{g_{\theta}}(x)} \\<br>&amp;= \int p_{data}(x) \log \frac{1}{q_{\phi}(y=1|x)} + \int p_{g_{\theta}}(x) \log \frac{1}{q_{\phi}(y=0|x)} \\<br>&amp;= E_{p_{data}(x)}\left[ \log D(x) \right] + E_{p_{g_{\theta}}(x)}\left[ \log (1-D(x)) \right]<br>\end{split}<br>$</p>
<p>我們得到跟原始GAN paper上熟悉的式子！</p>
<h4 id="Data-prior"><a href="#Data-prior" class="headerlink" title="Data prior"></a>Data prior</h4><p><a href="https://kexue.fm/archives/5716#一般框架" target="_blank" rel="noopener">用变分推断统一理解生成模型（VAE、GAN、AAE、ALI）By 苏剑林</a>文章中引入了$p(x)$當作先驗分佈，一開始不太理解文章與原始GAN的關係，後來經過一番梳理，發現原來只是先驗分佈的不同</p>
<p>$<br>\begin{split}<br>KL(p_{\theta}(x,y) || q_{\phi}(x,y))<br>&amp;= \int p_{data}(x) \log \frac{p_{data}(x)}{q_{\phi}(x,y=1)} + \int p_{g_{\theta}}(x) \log \frac{p_{g_{\theta}}(x)}{q_{\phi}(x,y=0)} \\<br>&amp;= \int p_{data}(x) \log \frac{p_{data}(x)}{q_{\phi}(y=1|x)p_{data}(x)} + \int p_{g_{\theta}}(x) \log \frac{p_{g_{\theta}}(x)}{q_{\phi}(y=0|x)p_{data}(x)} \\<br>&amp;= \int p_{data}(x) \log \frac{1}{q_{\phi}(y=1|x)} + \int p_{g_{\theta}}(x) \log \frac{1}{q_{\phi}(y=0|x)} + \int  p_{g_{\theta}}(x) \log \frac{p_{g_{\theta}}(x)}{p_{data}(x)} \\<br>&amp;= E_{p_{data}(x)}\left[ \log D(x) \right] +  E_{p_{g_{\theta}}(x)}\left[ \log (1-D(x)) \right] + KL(p_{g_{\theta}}(x) || p_{data}(x))<br>\end{split}<br>$</p>
<p>實務上，我們訓練生成器都只去優化第二項，引入Data prior後，整個優化項變成</p>
<p>$$<br>\mathbb{E}_{p_{g_{\theta}}(x)}\left[ \log (D(x)) \right] + KL(p_{g_{\theta}}(x) || p_{data}(x))<br>$$</p>
<p>我們假設$p_{data}(x)$可以由上一輪的$p_{g_{\theta^\prime}}(x)$近似，故帶入式子</p>
<p>$$<br>\mathbb{E}_{p_{g_{\theta}}(x)}\left[ \log (D(x)) \right] + KL(p_{g_{\theta}}(x) || p_{g_{\theta^\prime}}(x))<br>$$</p>
<p>生成器除了要去騙過判別器外，我們還要求生成器要跟過去的自己接近，意思就是不要更新太快，這個跟一些訓練GAN常用的技巧是相同的，例如gradient penalty，在<a href="https://kexue.fm/archives/5716#正则项" target="_blank" rel="noopener">蘇大神的文章中有做實驗</a>，真的會幫助GAN的訓練與結果</p>
<h2 id="結語"><a href="#結語" class="headerlink" title="結語"></a>結語</h2><p>這篇花了不少時間讀懂參考資料，用自己的理解再重新詮釋過，能用一致的角度來看這兩個模型，還是很有收穫的，也更能看清楚模型根本優劣，下一篇還沒想到要寫什麼，敬請期待！</p>
<h2 id="Refernece"><a href="#Refernece" class="headerlink" title="Refernece"></a>Refernece</h2><ul>
<li><a href="https://kexue.fm/archives/5716/" target="_blank" rel="noopener">用变分推断统一理解生成模型（VAE、GAN、AAE、ALI）By 苏剑林</a></li>
<li><a href="https://sailinglab.github.io/pgm-spring-2019/lectures/" target="_blank" rel="noopener">Lecture #17 (Eric): Deep generative models (part 1): Overview of the theoretical basis and connections of deep generative models</a></li>
<li><a href="https://arxiv.org/pdf/1706.00550.pdf" target="_blank" rel="noopener">On Unifying Deep Generative Models</a></li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://odie2630463.github.io/2019/10/23/pycon-pyro/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="odie">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="odie's whisper">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/23/pycon-pyro/" itemprop="url">Introduction to Deep  Probabilistic Programming with Pyro</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">發表於</span>
              
              <time title="創建於" itemprop="dateCreated datePublished" datetime="2019-10-23T23:51:50+08:00">2019-10-23</time>
            

            
            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分類於</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/probabilistic-programming/" itemprop="url" rel="index"><span itemprop="name">probabilistic programming</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>今年在 PyconTW 給的演講，主題是關於機率程式語言與Pyro，機器學習核心問題其中之一是如何建立機率模型，我們想要足夠複雜但又可以推論、訓練的模型，且方法要夠通用兼顧效率；如果有一個生成模型，我們能不斷的從模型抽樣產生樣本，我們就會知道說模型的哪些「設定或是輸入」會產出好的或是跟真實資料相似的樣本，我們可以透過抽樣來推估給定真實資料下，一些隱藏變量或是我們想估計的變數</p>
<p>用機率程式語言來描述一個生成模型或是資料產生的過程，我們可以很容易得去抽樣或是計算機率值，甚至不用去寫複雜的推論過程，機率語言很自然的提供了相對應的推論方法，這些設計都是嵌入在程式語言的設計中</p>
<p>機率程式語言除了建立生成模型，本質上它還是一個通用的程式語言，我們依然可以用它來寫各種複雜程式，例如下西洋棋或是影像渲染等等，這大幅擴展了生成模型所能定義的事，我們不只能去生成影像、語音等等資料，更可以去生成一連串的動作、或是經過渲染的影像，但這些因為都是用機率程式語言所寫的，完全都可以去推估程式中的變量，模型也當然能夠生成新的資料用於預測；認知科學家研究人類如何做決策的過程，常用機率程式語言去假設人類做決策的生成模型，並且給一些人類決策過程的資料，透過這樣來研究所假設的模型是否合理，除此之外，模型在輸出每次的決策同時都可以給出相對應的機率值，與程式內部的變量值，我們可以知道模型為何做這樣的決策，或是如何犯錯的</p>
<p>近年來結合深度學習與自動微分工具，有不少機率程式語言的研究相繼提出，雖然還尚未有殺手級的應用，但是我想這個領域一定會提供人工智慧領域發展很多的新觀點</p>
<iframe src="https://docs.google.com/presentation/d/e/2PACX-1vTb6LflvI1Q5kS5i3ZEuKQjwuKUTB5VhobSoQIzBtmt2FYRbySQmMpomlJzdS5-tkHEpwncroOT_U6t/embed?start=false&loop=false&delayms=3000" frameborder="0" width="960" height="569" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://odie2630463.github.io/2019/01/16/free-energy-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="odie">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="odie's whisper">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/16/free-energy-1/" itemprop="url">漫談 Free energy principle (ㄧ)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">發表於</span>
              
              <time title="創建於" itemprop="dateCreated datePublished" datetime="2019-01-16T17:15:18+08:00">2019-01-16</time>
            

            
            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分類於</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/free-energy/" itemprop="url" rel="index"><span itemprop="name">free energy</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>之前漫談了 Variational Inference ，基本上從機器學習與機率分佈近似的角度出發來談了理論與應用，我們旨在最小化ELBO，來最大化對於資料的解釋，而且從中學習到隱變量，且隱變量還能捕捉到資料潛在資訊，這樣的演算法非常精緻優雅，是我個人非常欣賞的模型；我們的大腦，或是更廣泛來說，一個需要與環境交互的生物或自組織系統，<em>隨時都在對抗失序(resisting a tendency to disorder)</em>，生命需要維持一定的秩序才能生存，各種生理運作都必須精準穩定維持某種秩序，<em>簡言之，維持穩定是生存的要務之一</em>。</p>
<p>對於大腦來說，所謂的穩定就是對於各種輸入大腦都能給予解釋，<em>大腦討厭surprise！</em>大腦討厭無法解釋的東西，或是與自己預期差異很大的狀況，所以大腦的任務就是解釋或是預測各種輸入，來減少遇到surprise，<strong>這個概念為 The free energy principle</strong>。</p>
<p>The free energy principle 跟 Variational Inference 非常有關係，核心數學概念是相同的，由Karl Friston於2005提出，2010年於Nature上有一篇完整的概念描述 <strong>The free-energy principle:a unified brain theory ?</strong>，本篇會基於此文章來跟大家介紹這個概念；另外，2017年 Rafal Bogacz 寫了一篇 <strong>A tutorial on the free-energy framework for modelling perception and learning</strong>，這篇帶領讀者入門一些計算細節，本系列會基於這兩篇文章內容與大家分享。</p>
<h2 id="The-free-energy-principle"><a href="#The-free-energy-principle" class="headerlink" title="The free energy principle"></a>The free energy principle</h2><p><img src="/media/15476205423036.jpg" alt="-w974"></p>
<ul>
<li>外部狀態(External states)：會依agent產生的action與隱變量$\vartheta$改變，同時受到隨機干擾$\tilde {w}$的影響</li>
<li>感知(Sensation)：觀測外部狀態$\tilde{x}$與隱變量$\vartheta$得到感知$\tilde{s}$</li>
<li>內部狀態(Internal states)：最小化Free energy得到最佳的解釋$\mu$</li>
<li>決策行為：最小化Free energy來得到最佳的行為$a$</li>
</ul>
<p>整個流程是一個動態的過程，每個變數都有初始值，透過這樣的循環，agent可以最大化對於環境狀態的了解，內部狀態$\mu$一開始可能完全是隨機的，但透過感知與行為來最小化Free energy，最後內部狀態會從外部狀態中獲取最多資訊</p>
<h3 id="Free-energy"><a href="#Free-energy" class="headerlink" title="Free energy"></a>Free energy</h3><p>其實Free energy就是我們之前提到過的ELBO，差異在於負號，我們希望最小化Free energy，而要最大化ELBO，不過其實從優化角度來看其實一樣</p>
<p>回顧一下ELBO，並且寫成另一個形式<br>$$<br>\begin{split}<br>\mathbb{E}_{q_{\phi}(z)}<br>        \left[<br>          \log \frac{p_{\theta}(x,z)}             {q_{\phi}(z)}\right] &amp;= \mathbb{E}\left[ \log p_{\theta}(x|z) \right] - KL(q_{\phi}(z) || p(z)) \\<br>          &amp;= \mathbb{E}\left[ \log p_{\theta}(x,z) \right] - \mathbb{H}\left[ q_{\phi}(z) \right]<br>\end{split}<br>$$</p>
<p>上述是以ELBO的角度，需要最大化ELBO，換到Free energy就加上負號，得到下圖的公式，接下來的描述也是以圖上的符號來說明：</p>
<p><img src="/media/15476226757989.jpg" alt="-w873"></p>
<h3 id="Free-energy-bound-on-suprise"><a href="#Free-energy-bound-on-suprise" class="headerlink" title="Free-energy bound on suprise"></a>Free-energy bound on suprise</h3><ul>
<li>$q(\vartheta | \mu)$ 係指給定內部狀態解釋$\mu$對環境隱變量$\vartheta$的條件機率，跟VI想法一樣，我們無法精確知道隱變量的分佈，只好用一個近似的分佈來估計，所以我們如果對環境有好的解釋，我們應該可以把隱變量估計得比較好</li>
<li>$p(\tilde { s } , \vartheta|m)$ 給定目前模型$m$，生成$\tilde{s},\vartheta$聯合機率分佈</li>
<li>可以對照上述ELBO式子，是完全對應的，整個Free energy 可以寫成 $F ( \tilde { s } , \mu )$，我們可以分別針對兩個變量來最小化</li>
</ul>
<h3 id="Perception-optimizes-predictions"><a href="#Perception-optimizes-predictions" class="headerlink" title="Perception optimizes predictions"></a>Perception optimizes predictions</h3><ul>
<li>$\mu = \arg \min F ( \tilde { s } , \mu )$</li>
<li>根據現在輸入的感知，調整內部狀態$\mu$來最小化$F$，這個跟VI做的事情一樣，去學習好的表徵</li>
</ul>
<h3 id="Action-minimizes-prediction-errors"><a href="#Action-minimizes-prediction-errors" class="headerlink" title="Action minimizes prediction errors"></a>Action minimizes prediction errors</h3><ul>
<li>$a = \arg \min F ( \tilde { s } , \mu )$</li>
<li>這裡就是有趣的地方了，其實除了可以透過改變解釋來減少$F$，agent也可以透過改變輸入的感知來優化，<em>意思是agent會去選擇比較符合期待感知輸入</em>，這個也稱為<strong>active inference</strong></li>
</ul>
<p>Agent長期而言希望能最小化surprise，其實就是在最小化Free energy，透過改變自己對於感知輸入的解釋，透過主動選擇感知輸入來源與行為，讓agent能快速的了解適應環境；Free energy 是很有機會做為大腦學習、控制的基礎理論，在 <strong>The free-energy principle:a unified brain theory ?</strong> 文中有介紹與其他現有理論的關係，像是 Neural coding、Bayesian brain hypothesis 等等</p>
<h2 id="結語"><a href="#結語" class="headerlink" title="結語"></a>結語</h2><p>智慧的本質到底是什麼？我們到底是如何快速的學習？又為何要學習？本篇介紹了The free energy principle，我想我們為了要生存，必須要抵抗<em>失序</em>，我們必須讓自己維持在一種認知穩地的狀態，這樣帶來的附加效益就是讓我們有快速的學習能力，最終我們成了一個強大的解釋與預測機器</p>
<p>下一篇會介紹 <strong>A tutorial on the free-energy framework for modelling perception and learning</strong> 這篇文章，提出一個神經網路的框架能執行基於Free energy principle的計算，相當有趣！敬請期待</p>
<h2 id="Refernece"><a href="#Refernece" class="headerlink" title="Refernece"></a>Refernece</h2><ul>
<li><a href="https://en.wikipedia.org/wiki/Free_energy_principle" target="_blank" rel="noopener">Free energy principle - Wiki</a></li>
<li><a href="https://www.researchgate.net/publication/41001209_Friston_KJ_The_free-energy_principle_a_unified_brain_theory_Nat_Rev_Neurosci_11_127-138" target="_blank" rel="noopener">The free-energy principle: a unified brain theory?</a></li>
<li><a href="https://www.sciencedirect.com/science/article/pii/S0022249615000759" target="_blank" rel="noopener">A tutorial on the free-energy framework for modelling perception and learning</a></li>
<li><a href="">Karl Friston 15分鐘訪談 - Free Energy Principle</a></li>
<li><a href="https://www.youtube.com/watch?v=dLXKFA33SSM&t=2642s" target="_blank" rel="noopener">Karl Friston 演講影片 - Free energy and active inference</a></li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://odie2630463.github.io/2018/09/20/vi-2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="odie">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="odie's whisper">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/20/vi-2/" itemprop="url">漫談 Variational Inference (二)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">發表於</span>
              
              <time title="創建於" itemprop="dateCreated datePublished" datetime="2018-09-20T17:21:57+08:00">2018-09-20</time>
            

            
            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分類於</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/variational-inference/" itemprop="url" rel="index"><span itemprop="name">variational inference</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本篇是漫談 Variational Inference 系列第二篇，<a href="https://odie2630463.github.io/2018/08/21/vi-1/">前一篇</a>介紹了隱變量模型並推導出了ELBO，而我們知道只要有辦法最大化ELBO，就可以去近似$\log_{\theta}p(x)$，但具體而言我們該如何計算呢？</p>
<p>今天我們來細談一下<a href="https://arxiv.org/abs/1312.6114" target="_blank" rel="noopener">Auto-encoding variational Bayes</a>這篇論文，基於最大化ELBO，引入深度神經網路、低變異的梯度訓練方法提出 <strong>Variational Autoencoder(VAE)</strong>，把VI方法應用推展至複雜真實資料上，並且有大規模訓練的優化方法，是一篇非常重要且值得一讀的論文！</p>
<h2 id="Auto-encoding-variational-Bayes"><a href="#Auto-encoding-variational-Bayes" class="headerlink" title="Auto-encoding variational Bayes"></a>Auto-encoding variational Bayes</h2><h3 id="Amortized-inference"><a href="#Amortized-inference" class="headerlink" title="Amortized inference"></a>Amortized inference</h3><p>隱變量模型假設下，每個訓練資料中的觀測變量$x^i$，都對應各自隱變量分佈$z^i \sim q_{\phi_i}(z)$，$z^i$我們稱為<strong>局部變數</strong>，而$\phi_i$為<strong>局部變數的參數</strong>；但是當有一個不在訓練資料的新觀測變量$x^j$時，我們沒有對應的隱變量$z^j$的分佈呀！而且訓練過程中需要儲存大量的局部變量，訓練資料集中每一個觀測資料都要分配一組參數來訓練，用這種方法大幅限制了隱變量模型的應用範圍</p>
<p>局部變量$(x^i ,z^i \sim q_{\phi_i}(z))$是個瓶頸，我們引入一個神經網路來直接從觀測變量去預測出隱變量$(x^i ,z^i \sim q_{\phi}(z|x))$，這個神經網路通常也稱為Inference network或是Encoder，此時$\phi$不在是局部變數的參數了，對於計算每個隱變量$z$都是用同樣一組$\phi$，所以是變成<strong>全局變量參數</strong>，再也不用去儲存每個隱變量，而是可以透過觀測變量來預測，就算對於新的資料也一樣，這個技巧稱為Amortized inference</p>
<p>所以我們把ELBO改成<br>$$<br>\mathbb{E}_{q_{\phi}(z|x)}\left[ \log p_{\theta}(x|z) \right] - KL(q_{\phi}(z|x) || p(z))<br>$$</p>
<p>$q_{\phi}(z|x)$把觀測變量轉換至隱變量，而$p_{\theta}(x|z)$則把隱變量轉換回觀測變量，這樣的架構組成為Encoder-Decoder自編碼器架構，故ELBO的第一項其實就是自編碼器的還原誤差，一個觀測變量經過編碼、解碼後要跟輸入盡可能相同</p>
<p><img src="/media/C8CD4EAE-330B-4369-BB79-BA974B69EA45.png" alt="C8CD4EAE-330B-4369-BB79-BA974B69EA45"><br>圖片來源：<a href="https://www.dropbox.com/s/dl/v6ua3d9yt44vgb3/cover_and_thesis.pdf" target="_blank" rel="noopener">VARIATIONAL INFERENCE &amp; DEEP LEARNING: A NEW SYNTHESIS
</a></p>
<h3 id="Black-Box-Variational-Inference"><a href="#Black-Box-Variational-Inference" class="headerlink" title="Black Box Variational Inference"></a>Black Box Variational Inference</h3><p>我們已經得到一個可以求解優化的式子，並且引入神經網路至框架中，最後就要來看看到底要怎麼訓練這個模型，當然拿出最常用的方法<strong>隨機梯度下降(SGD)</strong>來試看看囉</p>
<p>要用上SGD，要先知道$\theta,\phi$對目標函數的梯度該如何計算，首先來回憶一下目標函數：<br>$$<br>L(\phi,\theta) = \mathbb{E}_{q_{\phi}(z|x)}\left[ \log p_{\theta}(x|z) \right] - KL(q_{\phi}(z|x) || p(z))<br>$$</p>
<p>先來看$\nabla_{\theta}L(\phi,\theta)$長什麼樣子</p>
<p>$$<br>\nabla_{\theta} L(\phi,\theta)=  \mathbb{E}_{q_{\phi}(z|x)}\left[\nabla_{\theta} \log p_{\theta}(x|z) \right]<br>$$</p>
<p>因為$\theta$只跟$L(\phi,\theta)$的第一項有關係，所以直接對期望內的$\log p_{\theta}(x|z)$取微分，而第二項無關$\theta$直接為0</p>
<p>再來看$\nabla_{\phi}L(\phi,\theta)$，$\phi$同時跟兩個項都有關係，但仔細看第二項，當$q_{\phi}(z|x)$與$p(z)$都是高斯分佈時，其KL距離可以有公式解，故其對$\phi$的微分也有公式解，所以只有第一項是需要使用抽樣來近似梯度</p>
<p>$<br>\begin{split}<br>\nabla_{\phi}L(\phi,\theta) &amp;= \nabla_{\phi} \mathbb{E}_{q_{\phi}(z|x)}\left[\log p_{\theta}(x|z) \right] + \nabla_{\phi}KL(\dots)\\<br>&amp;\approx \nabla_{\phi} \int q_{\phi}(z|x) \log p_{\theta}(x|z) dz \\<br>&amp;\approx \int \nabla_{\phi}q_{\phi}(z|x) \log p_{\theta}(x|z) dz \\<br>&amp;\approx \int q_{\phi}(z|x)\nabla_{\phi}\log q_{\phi}(z|x) \log p(x|z) dz \\<br>&amp;\approx n \log p_{\theta}(x|z)\nabla_{\phi}\log q_{\phi}(z|x) \quad z \sim q_{\phi}(z|x)<br>\end{split}<br>$</p>
<p>推導過程中用上了一個技巧，稱為<strong>log-derivative trick</strong></p>
<p>$$<br>\nabla_{\phi}\log q_{\phi}(z|x) = \frac{\nabla_{\phi}q_{\phi}(z|x)}{q_{\phi}(z|x)}<br>$$</p>
<p>所以可以把$\nabla_{\phi}q_{\phi}(z|x)$代換掉，得到一個能用抽樣近似的式子。所以總結一下上述的推導，$\nabla_{\theta}L(\phi,\theta)$是在訓練我們的生成模型，也可以說是Decoder，最大化$p_{\theta}(x)=p_{\theta}(x|z)p(z)$，這裡等同於EM演算法中的M步驟；而$\nabla_{\phi}L(\phi,\theta)$含有兩個部分，一個部分是KL的微分項，有解析公式容易計算，但另一項的積分就只能靠抽樣來近似，抽樣出$z$並計算對$\phi$梯度與資料似然加總，得到沒有偏差(Unbiased)的梯度估計</p>
<h3 id="Reparametrization-based-low-variance-gradient-estimator"><a href="#Reparametrization-based-low-variance-gradient-estimator" class="headerlink" title="Reparametrization-based low-variance gradient estimator"></a>Reparametrization-based low-variance gradient estimator</h3><p>上一小節我們得到了參數對於目標函數的梯度，但還有個問題，就是$\nabla_{\phi}L(\phi,\theta)$的變異(variance)非常的大，$n \log p_{\theta}(x|z)$有可能會是非常大的值而使得梯度過大；梯度是向量來描述要往哪邊走，才會使得目標函數最小，當變異很大時，就像是每個人都說要往不同的方向走，到最後這些方向加總在一起反而依然在原地打轉，或是有一個人說要往某個方向走非常大的一步，大過於其他人而造成梯度是有偏誤的，雖然期望上$\nabla_{\phi}L(\phi,\theta)$是個不偏估計，但是梯度變異過大使得訓練參數很困難</p>
<p>本篇論文的另一個重點就是用上<strong>Reparametrization trick</strong>於梯度估計上，提出一個低變異的梯度估計方法，才使得VAE能穩定訓練；我們將隨機的抽樣過程 $z \sim q_{\phi}(z|x)$，改成一個決定性的計算過程，例如要從高斯分佈中抽樣，我們可以改成</p>
<p>$$<br>z = g_{\mu, \sigma}(\epsilon) = \mu + \epsilon \cdot \sigma, \quad \epsilon \sim N(0,1)<br>$$</p>
<p><img src="/media/7A9ABDDC-52AA-4946-961C-F2CE320DAA8F.png" alt="7A9ABDDC-52AA-4946-961C-F2CE320DAA8F"><br>圖片來源：<a href="https://www.dropbox.com/s/dl/v6ua3d9yt44vgb3/cover_and_thesis.pdf" target="_blank" rel="noopener">VARIATIONAL INFERENCE &amp; DEEP LEARNING: A NEW SYNTHESIS
</a></p>
<p>抽樣會使得梯度無法傳遞，就像左邊那張圖一樣，Z是一個隨機計算節點，經過Z後我們無法對之前的計算有任何資訊，自然也無法計算梯度，但改成Reparameterized form後，梯度就能順利回傳至參數上；另一點是有效減少梯度變異，原本梯度計算過程受$n \log p_{\theta}(x|z)$影響而造成變異過大，而現在我們只需要計算$\nabla_\phi f$的期望值，兩者數值大小差異很大，因此減少梯度變異使訓練過程穩定，才能用在複雜的資料集上</p>
<p>$$<br>\nabla_\phi \mathbb{E}_{z \sim q(z\mid x)}\left[ f(x,z) \right] = \mathbb{E}_{\epsilon \sim p(\epsilon)} \left[ \nabla _{\phi} f(x,g(\epsilon, x))\right]<br>$$</p>
<h2 id="結語"><a href="#結語" class="headerlink" title="結語"></a>結語</h2><p>本篇是漫談VI方法的第二篇，細談了VAE模型基礎，如何從ELBO對應到自編碼器架構，且$KL(q_{\phi}(z|x)||p(z))$也可以看成是一種正規化項，並提出改進的梯度估計方法，才能使得訓練模型成為可能，VAE是非常好的表徵學習方法，訓練穩定並能結合<a href="https://arxiv.org/abs/1406.5298" target="_blank" rel="noopener">半監督式學習</a>、<a href="https://arxiv.org/pdf/1803.10122.pdf" target="_blank" rel="noopener">增強學習</a>等技術，後續很多的理論改進應用延伸，值得關注與學習</p>
<p>下一篇會討論VAE與其他生成模型的關係，最近有一些工作討論將各種生成模型放入同一個框架內討論，敬請期待</p>
<h2 id="Refernece"><a href="#Refernece" class="headerlink" title="Refernece"></a>Refernece</h2><ul>
<li><a href="https://ermongroup.github.io/cs228-notes/extras/vae/" target="_blank" rel="noopener">CS228/The variational auto-encoder</a></li>
<li><a href="http://www.cs.columbia.edu/~blei/papers/RanganathGerrishBlei2014.pdf" target="_blank" rel="noopener">Black Box Variational Inference</a></li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://odie2630463.github.io/2018/09/09/transformer/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="odie">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="odie's whisper">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/09/09/transformer/" itemprop="url">Attention Is All You Need</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">發表於</span>
              
              <time title="創建於" itemprop="dateCreated datePublished" datetime="2018-09-09T16:18:25+08:00">2018-09-09</time>
            

            
            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分類於</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/paper/" itemprop="url" rel="index"><span itemprop="name">paper</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>序列資料模型我們常用LSTM、或是各種RNN的變形，在主流的各種任務上都取得了非常好的結果，如機器翻譯、序列生成等；但因為遞迴特性，訓練過程很難平行化計算，難以利用硬體加速，此外，RNN模型依然存在記憶遺忘問題，很難捕捉序列的長期關係</p>
<p>近年來出現不少不是基於RNN序列模型，這篇<a href="https://bair.berkeley.edu/blog/2018/08/06/recurrent/" target="_blank" rel="noopener">When Recurrent Models Don’t Need to be Recurrent</a>分析兩種模型於序列模型上的差異，非基於RNN模型如<a href="https://odie2630463.github.io/2018/04/01/wavenet/">之前介紹的Wavenet</a>，是一種Feed-Forward序列生成的模型，本篇要介紹的是<a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener">Attention Is All You Need</a>，論文名稱很霸氣，果然有實力要叫什麼名字都可以XD，模型完全只使用注意力機制來做序列模型，在機器翻譯任務上，不僅訓練速度快且效果也非常好，很值得來實作的一篇論文；在後續研究上，注意力機制被用在更多的領域上，例如<a href="https://arxiv.org/abs/1805.08318" target="_blank" rel="noopener">Self-Attention Generative Adversarial Networks</a>，本篇論文也是扮演重要的承先啟後角色</p>
<h2 id="Model-Architecture"><a href="#Model-Architecture" class="headerlink" title="Model Architecture"></a>Model Architecture</h2><p>論文提出模型稱為Transformer，這篇<a href="http://jalammar.github.io/illustrated-transformer/" target="_blank" rel="noopener">The Illustrated Transformer</a>介紹非常完整，而且還有動畫來說明，強烈建議先看看這篇，本篇文章就稍微偷懶只簡單談一下其中一些細節心得與看法</p>
<p><img src="/media/4656352C-84F1-47B2-9360-729C9EBF2546.png" alt="4656352C-84F1-47B2-9360-729C9EBF2546"></p>
<h3 id="Scaled-Dot-Product-Attention"><a href="#Scaled-Dot-Product-Attention" class="headerlink" title="Scaled Dot-Product Attention"></a>Scaled Dot-Product Attention</h3><p>注意力機制可以視為類似搜尋的過程，給一個你想搜尋的Query，Query去跟Key做內積看看相近程度，然後用softmax來正規化來得到注意力分佈，最後根據這個注意力分佈來加權Value得到結果，整個過程公式簡單明瞭，僅是矩陣相乘</p>
<p><img src="/media/EB3EFE51-9300-4E2B-A8D3-D61BF81FA0C1.png" alt="EB3EFE51-9300-4E2B-A8D3-D61BF81FA0"></p>
<h3 id="Multi-Head-Attention"><a href="#Multi-Head-Attention" class="headerlink" title="Multi-Head Attention"></a>Multi-Head Attention</h3><p>Multi-Head Attention其實也沒什麼，就只是把Q、K、Ｖ分成好幾個部份，然後經過Linear轉換，再將每個部份分別去做Scaled Dot-Product Attention最後黏起來，好處就是讓整個注意力機制過程變得更彈性、可訓練，每個部分可以有不一樣的注意力權重</p>
<p><img src="/media/3F201427-F154-4297-A0C7-5C4FB3F050CF.png" alt="3F201427-F154-4297-A0C7-5C4FB3F050CF"></p>
<h3 id="Encoder-amp-Decoder"><a href="#Encoder-amp-Decoder" class="headerlink" title="Encoder &amp; Decoder"></a>Encoder &amp; Decoder</h3><p>Encoder與Decoder都是由Block堆疊而成，Block裡面基本上由上一小節介紹的Multi-Head Attention與Feed Forward組成，但是EncoderBlock僅用到Self attention，意思是Multi-Head Attention中的Q,K,V都是同一個輸入</p>
<p><img src="/media/02EF842C-2429-4EF7-B08C-9A4331288E02.png" alt="02EF842C-2429-4EF7-B08C-9A4331288E02"></p>
<p>論文裡給了Encoder中5-6層的Attention結果，可以看到Self attention表示了句子中某一個字與其他字之間的關係，且因為是Multi-Head的關係，圖上有不同顏色區分不同部分；Encoder利用Self attention來提取整個序列的結構，且沒有沒有遺忘問題，序列上每個位置都與其他位置考慮到之間關係，計算也相當快速</p>
<p>Decoder在進行解碼時，也先做Self attention來把目標序列的結構考慮進來，然後再引入Encoder的訊息做Multi-Head Attention，最後預測出序列下一個位置</p>
<h2 id="Implement-and-Tricks"><a href="#Implement-and-Tricks" class="headerlink" title="Implement and Tricks"></a>Implement and Tricks</h2><p>我的<a href="https://github.com/odie2630463/transformer" target="_blank" rel="noopener">實作版本</a>，以pytorch實作並於IWSLT16英文-德語翻譯語料進行訓練與測試</p>
<h3 id="Data-preprocessing"><a href="#Data-preprocessing" class="headerlink" title="Data preprocessing"></a>Data preprocessing</h3><p>把原始資料變成可以訓練的Dataloader常常要花一番苦工，Pytorch提供一系列不同的工具，像是<a href="https://github.com/pytorch/vision" target="_blank" rel="noopener">torchvision</a>、<a href="http://pytorch.org/audio/#torchaudio" target="_blank" rel="noopener">torchaudio</a>、<a href="https://github.com/pytorch/text" target="_blank" rel="noopener">torchtext</a>，裡面有一些整理好的資料集或是常用函數，不論是要自己重新做一個新資料集或是直接使用都非常方便，而且減少錯誤機會，所以基本上我不太喜歡自己去重寫資料整理的部分，而是去學習使用已有且穩定的套件</p>
<p>torchtext其實是有直接提供IWSLT16 dataloader使用，但是有些錯誤，所以沒辦法順利直接利用，那只好利用所提供的函數自己來做一個囉</p>
<p>要做一個翻譯的資料集相當簡單，只需要把語料資料整理成兩個文件(也可以是多個，用檔名區分即可)分別對應，像是這樣：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#train.de.txt</span><br><span class="line"></span><br><span class="line">David Gallo: Das ist Bill Lange. Ich bin Dave Gallo.</span><br><span class="line">Wir werden Ihnen einige Geschichten über das Meer in Videoform erzählen.</span><br><span class="line">Wir haben ein paar der unglaublichsten Aufnahmen der Titanic, die man je gesehen hat,, und wir werden Ihnen nichts davon zeigen.</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#train.en.txt</span><br><span class="line"></span><br><span class="line">David Gallo: This is Bill Lange. I&apos;m Dave Gallo.</span><br><span class="line">And we&apos;re going to tell you some stories from the sea here in video.</span><br><span class="line">We&apos;ve got some of the most incredible video of Titanic that&apos;s ever been seen, and we&apos;re not going to show you any of it.</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<p>用spacy來做斷詞，並告訴torchtext.data.Field所使用的斷詞器、與相關參數設定</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">spacy_de = spacy.load(<span class="string">'de'</span>)</span><br><span class="line">spacy_en = spacy.load(<span class="string">'en'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tokenize_en</span><span class="params">(text)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> [tok.text <span class="keyword">for</span> tok <span class="keyword">in</span> spacy_en.tokenizer(text)]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tokenize_de</span><span class="params">(text)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> [tok.text <span class="keyword">for</span> tok <span class="keyword">in</span> spacy_de.tokenizer(text)]</span><br><span class="line"></span><br><span class="line">DE = data.Field(tokenize=tokenize_de,</span><br><span class="line">                init_token=<span class="string">'&lt;SOS&gt;'</span>,</span><br><span class="line">                eos_token=<span class="string">'&lt;EOS&gt;'</span>,</span><br><span class="line">                fix_length=<span class="number">20</span>,</span><br><span class="line">                lower=<span class="keyword">True</span>,</span><br><span class="line">                batch_first=<span class="keyword">True</span>)</span><br><span class="line">EN = data.Field(tokenize=tokenize_en,</span><br><span class="line">                init_token=<span class="string">'&lt;SOS&gt;'</span>,</span><br><span class="line">                eos_token=<span class="string">'&lt;EOS&gt;'</span>,</span><br><span class="line">                lower=<span class="keyword">True</span>,</span><br><span class="line">                fix_length=<span class="number">20</span>,</span><br><span class="line">                batch_first=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>

<p>用torchtext.datasets.TranslationDataset把語料包裝成datasets</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">train = datasets.TranslationDataset(path=<span class="string">'./data/train'</span>, </span><br><span class="line">                                    exts=(<span class="string">'.de.txt'</span>, <span class="string">'.en.txt'</span>),</span><br><span class="line">                                    fields=(DE, EN))</span><br></pre></td></tr></table></figure>

<p>還有製作字典</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">DE.build_vocab(train.src, min_freq=<span class="number">3</span>)</span><br><span class="line">EN.build_vocab(train, max_size=<span class="number">50000</span>)</span><br></pre></td></tr></table></figure>

<p>最後就可以包裝成Dataloader了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">train_iter = data.BucketIterator(dataset=train, </span><br><span class="line">                                 batch_size=<span class="number">32</span>,</span><br><span class="line">                                 sort_key=<span class="keyword">lambda</span> x: data.interleave_keys(len(x.src), len(x.trg)))</span><br><span class="line">                                 </span><br><span class="line">train_batch = next(iter(train_iter))</span><br><span class="line">train_batch[<span class="number">0</span>].src</span><br><span class="line">&gt; tensor([[   <span class="number">2</span>,    <span class="number">6</span>,  <span class="number">195</span>,  <span class="number">437</span>,   <span class="number">13</span>,   <span class="number">82</span>, <span class="number">2076</span>,    <span class="number">0</span>,    <span class="number">5</span>,    <span class="number">3</span>,    <span class="number">1</span>,    <span class="number">1</span>,</span><br><span class="line">            <span class="number">1</span>,    <span class="number">1</span>,    <span class="number">1</span>,    <span class="number">1</span>,    <span class="number">1</span>,    <span class="number">1</span>,    <span class="number">1</span>,    <span class="number">1</span>]], device=<span class="string">'cuda:0'</span>)</span><br></pre></td></tr></table></figure>

<p>以上很簡單介紹用法，這裡還有兩篇(<a href="https://zhuanlan.zhihu.com/p/37223078" target="_blank" rel="noopener">1</a>,<a href="https://zhuanlan.zhihu.com/p/31139113" target="_blank" rel="noopener">2</a>)不錯的教學，大家可以參考</p>
<h3 id="Mask-is-important"><a href="#Mask-is-important" class="headerlink" title="Mask is important"></a>Mask is important</h3><p>Transformer模型不難理解與實作，但是有個小地方尤其重要，就是<strong>輸入需要很仔細地做Mask</strong>，非Recurrent模型有個問題，就是輸入長度、大小都必須要是固定的，不管句子長短，要輸入至模型都需要截長補短至固定長度，所以當句子短時候，後面會補上PAD來填滿長度，但是些部分是不能參與至注意力過程的，所以我們每次去做矩陣相成後，需要把某些部分遮起來</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">output = torch.bmm(Q,K.transpose(<span class="number">1</span>,<span class="number">2</span>))</span><br><span class="line">output = output / ( self.hidden_size**<span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">queries_mask_ = torch.cat([queries_mask]*self.num_head,<span class="number">0</span>).float()</span><br><span class="line">keys_mask_ = torch.cat([keys_mask]*self.num_head,<span class="number">0</span>).float()</span><br><span class="line">output_mask = <span class="number">1</span> - queries_mask_.bmm(keys_mask_.transpose(<span class="number">1</span>,<span class="number">2</span>)).float()</span><br><span class="line">output_ = output.masked_fill(output_mask.byte() , <span class="number">-2</span>**<span class="number">32</span>)</span><br></pre></td></tr></table></figure>

<p>這部分可以配合實作一起看會比較清楚，queries_mask_與keys_mask_是輸入時候給的，告訴模型這個序列的長度資訊，是PAD地方為0其餘為1</p>
<p>既然output是Q,K相乘，我們如果把他們的mask也相乘，就可以得到正確的mask，mask為0的地方代表是PAD去做注意力過程，應該要被忽略</p>
<p>最後用masked_fill來把要忽略的位置填上一個很小的數值，因為masked_fill是把為1的地方填上，所以之前算出來的mask要做反轉，至於為何要填上很小的負數值是因為等一下要做softmax，如果單純填上0，經過softmax可能不為0</p>
<h3 id="Causality-is-important"><a href="#Causality-is-important" class="headerlink" title="Causality is important"></a>Causality is important</h3><p>Decoder在解碼的時候是基於過去的序列來預測下一個位置，當然不能看到未來的訊息，所以Decoder裡做Self attention要把未來資訊遮蔽，實作上很簡單就是做一個上三角矩陣，但是要保留對角線部分</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">if self.causality:</span><br><span class="line">    bs,s1,s2 = output_mask.size()</span><br><span class="line">    tri = np.triu(np.ones((s1,s2))) - np.eye(s1,s2)</span><br><span class="line">    tri = torch.from_numpy(tri).to(output_mask.device)</span><br><span class="line">    tri = torch.stack([tri]*bs,0).byte()</span><br><span class="line">    output_ = output_.masked_fill(tri , -2**32)</span><br></pre></td></tr></table></figure>

<p>這樣就能保證Decoder訓練過程不會去偷看到下一個位置，只能用自己現在與過去的位置資訊來預測</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://arxiv.org/abs/1706.03762" target="_blank" rel="noopener">Attention Is All You Need</a></li>
<li><a href="http://jalammar.github.io/illustrated-transformer/" target="_blank" rel="noopener">The Illustrated Transformer</a></li>
<li><a href="http://nlp.seas.harvard.edu/2018/04/03/attention.html" target="_blank" rel="noopener">The Annotated Transformer</a></li>
<li><a href="https://github.com/Kyubyong/transformer" target="_blank" rel="noopener">Kyubyong/transformer</a></li>
<li><a href="https://github.com/jadore801120/attention-is-all-you-need-pytorch" target="_blank" rel="noopener">jadore801120/attention-is-all-you-need-pytorch</a></li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://odie2630463.github.io/2018/08/21/vi-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="odie">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="odie's whisper">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/21/vi-1/" itemprop="url">漫談 Variational Inference (一)</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">發表於</span>
              
              <time title="創建於" itemprop="dateCreated datePublished" datetime="2018-08-21T16:13:27+08:00">2018-08-21</time>
            

            
            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分類於</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/variational-inference/" itemprop="url" rel="index"><span itemprop="name">variational inference</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Variational Inference 是一種近似複雜分佈的數學方法，我們假設一類計算簡單的<strong>候選分佈</strong>$q(z)$，並有另一個複雜難以計算的後驗分佈$p(z|x)$，我們希望從候選分佈中找一個最接近$p(z|x)$的$q^*(z)$，這個等同於最小化$KL(q(z) | p(z|x))$</p>
<p>不過為什麼我們要近似後驗分佈$p(z|x)$呢？或是$q(z)$可以怎麼定義？與深度學習怎麼結合？本篇或接下來的幾篇文章就來跟大家漫談一下VI，整理了自己看過有關的資料，從幾個角度切入推導，並來看看跟其他生成模型有什麼關係</p>
<h2 id="Latent-variable-model"><a href="#Latent-variable-model" class="headerlink" title="Latent variable model"></a>Latent variable model</h2><p>要談VI之前要先講一下隱變量模型(Latent variable model)，因為VI就是拿來求解隱變量模型方法之一，我們假設可觀測的隨機變數$x$與無法觀測的隱變量$z$聯合機率分佈為：</p>
<p>$$<br>p_{\theta}(x,z) = p_{\theta}(x|z)p(z)<br>$$</p>
<p>其中$p_{\theta}(x|z)$為一個參數化的模型來表示條件機率，再透過把$z$積分，我們可以得到$p(x)$：</p>
<p>$$<br>p_{\theta}(x) = \int p_{\theta}(x,z)dz<br>$$</p>
<p>看來很完美，我們得到$p(x)$式子接著就能直接去用MLE去學習 $\theta$ 囉！</p>
<p>這裡再多討論一下為何要使用隱變量模型，從上面式子來看，引入隱變量可以幫助我們定義出一個能計算的$p(x)$，解決了不知道怎麼假設$p(x)$的問題；另外，隱變量能捕捉資料所隱含的特性，例如「星座」是人們所加上的隱變量，有時候透過「星座」可以更快掌握你是個怎樣的人或是個性，或是說從你的行為來猜測你是什麼星座之類的，都是生活中常見的隱變量應用</p>
<p>不過更多時候，隱變量於表徵學習任務上扮演重要的角色，像是這個<a href="https://arxiv.org/abs/1704.03477" target="_blank" rel="noopener">手繪塗鴉</a>的例子，所學習到的隱變量於低維度可以形成<a href="https://zh.wikipedia.org/wiki/流形" target="_blank" rel="noopener">流型(Manifolds)</a>，隱變量能捕捉資料的變異性，形成一個漸變的空間且具有泛化能力，代表隱變量能更好的表示資料特性，是很好的表徵學習方法</p>
<p><img src="/media/15342296556201.png" alt="-w401"></p>
<h2 id="計算後驗機率困難"><a href="#計算後驗機率困難" class="headerlink" title="計算後驗機率困難"></a>計算後驗機率困難</h2><p>我們先來看看為什麼要近似$p(z|x)$，從隱變量模型，我們有一個可以計算的$p(x,z)$，現在把$p(x)$重新寫成：</p>
<p>$$<br>p(x) = \frac{p(x,z)}{p(z|x)}<br>$$</p>
<p>又是另一片天地，我們想要能計算$p(x)$，那只要$p(x,z)$與$p(z|x)$都可以被計算，那一切就太好了；只可惜，$p(z|x)$是無法被計算的，原因是：</p>
<p>$$<br>p(z|x) = \frac{p(x,z)}{p(x)}<br>$$</p>
<p>又導回來了，我們就是苦於沒有$p(x)$呀，那只好直接用另一個$q(z)$來偽裝成$p(z|x)$了，如果他們兩個夠相似，$p(x)$應該是可以被近似求出來的，這裡就用上VI想法了！</p>
<h2 id="Evidence-Lower-Bound"><a href="#Evidence-Lower-Bound" class="headerlink" title="Evidence Lower Bound"></a>Evidence Lower Bound</h2><p>我們希望用上$q_{\phi}(z)$來取代$p_{\theta}(z|x)$解決後驗計算困難問題，所以引入$q_{\phi}(z)$至$p(x)$得到：</p>
<p>$<br>\begin{split}<br>\log p_{\theta}(x) &amp;= \mathbb{E}_{q_{\phi}(z)} \left[ \log p_{\theta}(x) \right] \\<br>          &amp;= \mathbb{E}_{q_{\phi}(z)} \left[ \log \frac{p_{\theta}(x,z)}{p_{\theta}(z|x)} \right] \\<br>&amp;= \mathbb{E}_{q_{\phi}(z)}<br>          \left[<br>          \log \frac{p_{\theta}(x,z)}{q_{\phi}(z)} \frac{q_{\phi}(z)}{p_{\theta}(z|x)}<br>          \right] \\<br>&amp;= \mathbb{E}_{q_{\phi}(z)}<br>          \left[<br>          \log \frac{p_{\theta}(x,z)}{q_{\phi}(z)}\right] + \mathbb{E}_{q_{\phi}(z)} \left[ \log \frac{q_{\phi}(z)}{p_{\theta}(z|x)}<br>          \right] \\<br>&amp;= \mathbb{E}_{q_{\phi}(z)}<br>        \left[<br>          \log \frac{p_{\theta}(x,z)}             {q_{\phi}(z)}\right] + KL(q_{\phi}(z)|| p_{\theta}(z|x))<br>\end{split}$</p>
<p>我們將原本$\log_{\theta} p(x)$拆成兩項，先來看第二項，為我們VI方法裡面的候選分佈$q_{\phi}(z)$與後驗分佈$p_{\theta}(z|x)$的KL距離，一定大於等於0，但我們依然無法直接去最小化之間差距</p>
<p>所以轉看第一項，又因$\log p(x)$為一個定值，第一項就成為了一個下界(Lower Bound)並稱為Evidence Lower Bound(ELBO)，如果我們最大化第一項，不就等同於最小化第二項了嗎！而且第一項完全是可以算的！我們能透過訓練參數$\theta , \phi$來最大化ELBO，同時也減少$q_{\phi}(z)$與$p_{\theta}(z|x)$KL距離</p>
<p>最後整理成一般常看到ELBO形式</p>
<p>$$<br>\mathbb{E}_{q_{\phi}(z)}<br>        \left[<br>          \log \frac{p_{\theta}(x,z)}             {q_{\phi}(z)}\right] = \mathbb{E}\left[ \log p_{\theta}(x|z) \right] - KL(q_{\phi}(z) || p(z))<br>$$</p>
<h2 id="Importance-Sampling-to-ELBO"><a href="#Importance-Sampling-to-ELBO" class="headerlink" title="Importance Sampling to ELBO"></a>Importance Sampling to ELBO</h2><p>剛剛我們由計算後驗分佈困難而推導出了ELBO，這次我們從 Importance Sampling 出發來推出ELBO，計算$p_{\theta}(x)$是求解一個複雜的積分：<br>$$<br>p_{\theta}(x) = \int p_{\theta}(x|z)p(z)dz<br>$$</p>
<p>我們可以用 Importance Sampling 來近似這個積分，用一個簡單的$q_{\phi}(z)$來抽樣出$z$，並且根據$\frac{q_{\phi}(z)}{p(z)}$來決定抽樣出的樣本權重：</p>
<p>$<br>\begin{split}<br>p_{\theta}(x) &amp;= \int p_{\theta}(x|z) \frac{p(z)}{q_{\phi}(z)} q_{\phi}(z)dz \\<br>&amp;= \int p_{\theta}(x|z)w^{(s)}q_{\phi}(z)dz \quad w^{(s)} = \frac{p(z)}{q_{\phi}(z)} \\<br>&amp;\approx \frac{1}{S} \sum w^{(s)}p(x|z^{(s)})<br>\end{split}$</p>
<p>這裡用上<a href="https://zh.wikipedia.org/wiki/延森不等式" target="_blank" rel="noopener">Jensen’s inequality</a>：</p>
<p>$$<br>\log \int p(x)g(x) dx \ge \int p(x) \log g(x) dx<br>$$</p>
<p>代入得到：</p>
<p>$<br>\begin{split}<br>\log p_{\theta}(x) &amp;= log \int p_{\theta}(x|z) \frac{p(z)}{q_{\phi}(z)} q(z) dz \\<br>&amp;\ge \int q_{\phi}(z) \log \left[ p_{\theta}(x|z)\frac{p(z)}{q_{\phi}(z)}  \right] dz = \int q_{\phi}(z) \log_{\theta}(x|z) - \int q_{\phi}(z) \log \frac{q_{\phi}(z)}{p(z)} \\<br>\end{split}$</p>
<p>最後將式子整理成：</p>
<p>$$<br>\int q_{\phi}(z) \log_{\theta}(x|z) - \int q_{\phi}(z) \log \frac{q_{\phi}(z)}{p(z)} = \mathbb{E}\left[ \log p_{\theta}(x|z) \right] - KL(q_{\phi}(z) || p(z))<br>$$</p>
<h2 id="Variational-EM"><a href="#Variational-EM" class="headerlink" title="Variational EM"></a>Variational EM</h2><p>最後我們來給一個具體常用來求解隱變量模型的演算法，最大期望演算法(Expectation-Maximization Algorithm,EM)，這裡不打算從頭講起EM，但是這個演算法相當重要，值得深入了解，我推薦最近剛結束的<a href="http://deepbayes.ru/#materials" target="_blank" rel="noopener">DeepBayes課程</a>，裡面非常詳細介紹了EM方法，本小節也有參考課程資料</p>
<p>用EM求解高斯混和模型(Gaussian Mixed Model)時候，因為高斯分佈良好的性質，所以能很方便地得到公式解：</p>
<ul>
<li>E-step：$q(z) = p(z|x,\theta)$</li>
<li>Ｍ-step：$\max\limits_{\theta} \mathbb{E}\left[ \log p_{\theta}(x,z) - \log q(z) \right]$</li>
</ul>
<p>可以看到在E-step時候，$q(z)$總是有公式解，故我們是有一個最優的$q(z)$恰好等於$p(z|x)$，也就等於最小化$KL(q(z)|p(z|x))$為0，M-step訓練參數$\theta$來最大化$\log p_{\theta}(x)$，此時ELBO直接等於$\log p_{\theta}(x)$</p>
<p>但很多時候我們無法寫出E-step的公式解，所以我們就用上VI方法，並且假設候選分佈為一個簡單且每個分量皆為獨立的分佈$q(z)=\prod q(z_i)$，稱為Mean-Field Approximation，我們帶入回ELBO中可以得到</p>
<p>$<br>\begin{split}<br>ELBO(q, \theta) &amp; = \int \prod_i q_i(z_i) \Big[ \log p_{\theta}(x,z) - \sum_i \log q_i(z_i) \Big ]dz \\<br>&amp; = \int q_j(z_j) \Big [ \int \log p_{\theta}(x,z) \prod_{i \neq j} q_i(z_i)dz_i \Big ] dz_j - \int \sum_{i \neq j} \log q_i(z_i) \prod_{i \neq j} q_i(z_i)dz_i - \int q_i(z_i) \log q_i(z_i)dz_i \\<br>&amp; = \int q_j(z_j) \log \tilde p(x,z_j)dz_j - \int q_j(z_j) \log q_j(z_j) dz_j + const \\<br>&amp; = -KL(q_j(z_j) || \tilde p(x,z_j))<br>\end{split}<br>$</p>
<p>最後 Variational EM 我們可以寫成</p>
<ul>
<li>E-step：$q_j(z_j) \propto \tilde p(x,z_j)$</li>
<li>Ｍ-step：$\max\limits_{\theta} \mathbb{E}\left[ \log p_{\theta}(x,z) - \log q(z) \right]$</li>
</ul>
<p>計算$q_j(z_j) = \mathbb{E}_{i \neq j}\left[ \log p(x,z) \right]$，固定$z_j$然後將j以外的維度進行積分，白話一點就是固定一個維度，把其他維度的所有組合都試過一次來計算這個維度的機率分佈，涉及非常大量的計算，雖然Mean-Field Approximation一定能寫成這樣的解，但是很多時候依然無法計算</p>
<h2 id="結語"><a href="#結語" class="headerlink" title="結語"></a>結語</h2><p>本篇是漫談VI方法的第一篇，介紹了隱變量模型與其求解困難，並用上VI方法來求解模型，得出可以透過最大化ELBO來求解訓練參數，最後介紹了Variational EM方法與限制</p>
<p>第一篇算是基礎介紹，也是我論文裡文獻回顧又再回顧一次，介紹了兩種角度推導出ELBO，下一篇我打算來介紹與深度學習如何結合，突破Mean-Field Approximation限制，成為生成模型中一個重要的方法，敬請期待</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li>NIPS 2016 Tutorial，很完整介紹VI的發展歷史 <a href="https://media.nips.cc/Conferences/2016/Slides/6199-Slides.pdf" target="_blank" rel="noopener">Variational Inference: Foundations and Modern Methods</a></li>
<li>Shakir Mohamed 大神的教學投影片<a href="https://www.shakirm.com/papers/VITutorial.pdf" target="_blank" rel="noopener">Variational Inference for Machine Learning</a></li>
<li>VAE 提出者的博士論文，值得一看！<a href="https://www.dropbox.com/s/dl/v6ua3d9yt44vgb3/cover_and_thesis.pdf" target="_blank" rel="noopener">VARIATIONAL INFERENCE &amp; DEEP LEARNING: A NEW SYNTHESIS
</a></li>
<li><a href="https://chrischoy.github.io/research/Expectation-Maximization-and-Variational-Inference/" target="_blank" rel="noopener">Expectation Maximization and Variational Inference</a></li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://odie2630463.github.io/2018/07/28/pyro-lda/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="odie">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="odie's whisper">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/07/28/pyro-lda/" itemprop="url">LDA model use Pyro</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">發表於</span>
              
              <time title="創建於" itemprop="dateCreated datePublished" datetime="2018-07-28T21:21:44+08:00">2018-07-28</time>
            

            
            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分類於</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/probabilistic-programming/" itemprop="url" rel="index"><span itemprop="name">probabilistic programming</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><a href="http://pyro.ai" target="_blank" rel="noopener">Pyro</a> 是一個由Uber AI Lab所開發的Probabilistic Programming Language(PPL)，用程式語言來描述具有隨機性的程序或是過程；從另一個角度來看，圖機率模型(PGM)是用圖的方式來描述一個機率過程，而PPL則是可以讓你用上程式語言來描述，條件、迴圈等等都可以用上，能描述更為複雜的機率過程</p>
<p>PPL也存在好一陣子了，像是MIT基於LISP所開發的<a href="https://arxiv.org/abs/1206.3255" target="_blank" rel="noopener">Church</a>、<a href="http://webppl.org" target="_blank" rel="noopener">webppl</a>都是，但都偏向是學術性的語言；隨著深度學習也用上了一些機率推斷方法，像是MCMC、Variational inference等，也出現基於Tensorflow、Pytorch框架的PPL，能更好的與深度學習方法結合，並且引入很多有用的機率數學工具</p>
<h2 id="Introduction-of-Pyro"><a href="#Introduction-of-Pyro" class="headerlink" title="Introduction of Pyro"></a>Introduction of Pyro</h2><p>根據官網描述，Pyro有幾個特點</p>
<ul>
<li>Universal: Pyro can represent any computable probability distribution.</li>
<li>Scalable: Pyro scales to large data sets with little overhead.</li>
<li>Minimal: Pyro is implemented with a small core of powerful, composable abstractions.</li>
<li>Flexible: Pyro aims for automation when you want it, control when you need it. </li>
</ul>
<p>基於Pytorch開發，所以深度學習那些當然都可以整合一起用上，並且語法非常的Pythonic，也用上了很多高階特性，例如context manager，機率推斷演算法主要提供Stochastic Variational Inference(SVI)，可以用上SGD來訓練模型，整體上的確以最小需要、高彈性、透明為主要設計，相較於基於Tensorflow的<a href="http://edwardlib.org" target="_blank" rel="noopener">Edward</a>、<a href="https://github.com/tensorflow/probability" target="_blank" rel="noopener">Tensorflow_probability</a>，提供不只VI相關演算法，還有很多MCMC相關的，或是<a href="https://odie2630463.github.io/2018/07/11/flow/">前一篇提到的NF</a>，更多工具可以使用，但也相對不是那麼容易上手；不過結合更多機率特性是趨勢之一，這兩個主流的Deep PPL都很值得關注與學習。</p>
<h2 id="Implement-LDA-model"><a href="#Implement-LDA-model" class="headerlink" title="Implement LDA model"></a>Implement LDA model</h2><p>以上介紹了Pyro，接著就來實作Latent Dirichlet allocation(LDA)模型，常用文本主題分析，且為圖機率模型的經典模型！接著用Pyro與SVI來實作並求解參數，本文並不會從頭介紹Pyro基礎，建議可以先看<a href="http://pyro.ai/examples/index.html" target="_blank" rel="noopener">官網教學</a>，程式碼我放在<a href="https://colab.research.google.com/drive/11NIOR7Ix2pxkQPw_m0zZaai9Fi935-l7" target="_blank" rel="noopener">Colab</a>，大家可以直接跑看看</p>
<h4 id="Model"><a href="#Model" class="headerlink" title="Model"></a>Model</h4><p>我們就直接從模型看起，先來看一下LDA式子長怎樣，$\phi$指每個字對應個主題的機率分佈，$\theta_d$指每一文件對應主題的機率分佈，$z$指每個字被分配到的主題，式子可以寫成：</p>
<p>$$<br>p(\phi,\theta,z,w) = p(\phi) \prod_{d=1}^D \prod_{n=1}^{N_d} p(z_{dn}|\theta_d)p(w_{dn}|z_{dn},\phi)<br>$$</p>
<p>式子對應Pyro程式碼如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@pyro.poutine.broadcast</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">model</span><span class="params">(data)</span>:</span></span><br><span class="line">  phi = pyro.sample(<span class="string">"phi"</span>,dist.Dirichlet(torch.ones([K, V])).independent(<span class="number">1</span>))</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">for</span> d <span class="keyword">in</span> pyro.irange(<span class="string">"documents"</span>, D):</span><br><span class="line">    theta_d = pyro.sample(<span class="string">"theta_%d"</span>%d, dist.Dirichlet(torch.ones([K])))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> pyro.iarange(<span class="string">"words_%d"</span>%d, N[d]):</span><br><span class="line">      z = pyro.sample(<span class="string">"z_%d"</span>%d, dist.Categorical(theta_d))</span><br><span class="line">      pyro.sample(<span class="string">"w_%d"</span>%d, dist.Categorical(phi[z]), obs=data[d])</span><br></pre></td></tr></table></figure>

<h4 id="Guide"><a href="#Guide" class="headerlink" title="Guide"></a>Guide</h4><p>$w$是已知觀測變量，想要估計的隱變量有$\phi,\theta,z$，我們可以用上Variational inference方法來最大化資料似然$\log p(w)$，並用另一個<strong>guide</strong>來近似$p(\phi,\theta,z|w)$，有關於VI相關會在後續寫個幾篇好好來講講</p>
<p>$$<br>q(\phi,\theta,z) = q(\phi) \prod_{d=1}^D q(\theta_d)\prod_{n=1}^{N_d} q(z_{dn})<br>$$</p>
<p>式子對應Pyro程式碼如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@pyro.poutine.broadcast</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">guide</span><span class="params">(data)</span>:</span></span><br><span class="line">  beta_q = pyro.param(<span class="string">"beta_q"</span>, torch.ones([K, V]),constraint=constraints.positive)</span><br><span class="line">  phi_q = pyro.sample(<span class="string">"phi"</span>,dist.Dirichlet(beta_q).independent(<span class="number">1</span>))</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">for</span> d <span class="keyword">in</span> pyro.irange(<span class="string">"documents"</span>, D):</span><br><span class="line">    alpha_q = pyro.param(<span class="string">"alpha_q_%d"</span>%d, torch.ones([K]),constraint=constraints.positive)</span><br><span class="line">    q_theta_d = pyro.sample(<span class="string">"theta_%d"</span>%d, dist.Dirichlet(alpha_q))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> pyro.iarange(<span class="string">"words_%d"</span>%d, N[d]):</span><br><span class="line">      q_i = pyro.param(<span class="string">"q_%d"</span>%d, torch.randn([N[d], K]).exp(),</span><br><span class="line">                       constraint=constraints.simplex)</span><br><span class="line">      pyro.sample(<span class="string">"z_%d"</span>%d, dist.Categorical(q_i))</span><br></pre></td></tr></table></figure>

<p>注意<strong>guide</strong>裡面有參數是需要訓練的，比如每一個字所對應的$z_dn$，我們都用一個Categorical分佈來代表主題，都有參數需要訓練，很直接去估文件裡的每個字代表什麼主題</p>
<h4 id="Training"><a href="#Training" class="headerlink" title="Training"></a>Training</h4><p>最後用SVI去最大化ELBO</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">adam_params = &#123;<span class="string">"lr"</span>: <span class="number">0.01</span>, <span class="string">"betas"</span>: (<span class="number">0.90</span>, <span class="number">0.999</span>)&#125;</span><br><span class="line">optimizer = Adam(adam_params)</span><br><span class="line"></span><br><span class="line">svi = SVI(model, config_enumerate(guide, <span class="string">'parallel'</span>), optimizer, loss=TraceEnum_ELBO(max_iarange_nesting=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">3000</span>):</span><br><span class="line">  loss = svi.step(data)</span><br></pre></td></tr></table></figure>

<p>TraceEnum_ELBO適用於有離散變量需要估計的時候，會直接去做enumerate，不然單用Trace_ELBO遇到離散變量效果都很差</p>
<h4 id="Result"><a href="#Result" class="headerlink" title="Result"></a>Result</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">pyro.param(<span class="string">'q_2'</span>)</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">tensor([[<span class="number">0.8072</span>, <span class="number">0.0559</span>, <span class="number">0.0606</span>, <span class="number">0.0543</span>, <span class="number">0.0220</span>],</span><br><span class="line">        [<span class="number">0.9249</span>, <span class="number">0.0258</span>, <span class="number">0.0146</span>, <span class="number">0.0242</span>, <span class="number">0.0104</span>],</span><br><span class="line">        [<span class="number">0.9250</span>, <span class="number">0.0258</span>, <span class="number">0.0145</span>, <span class="number">0.0243</span>, <span class="number">0.0105</span>],</span><br><span class="line">        [<span class="number">0.3842</span>, <span class="number">0.0408</span>, <span class="number">0.5215</span>, <span class="number">0.0381</span>, <span class="number">0.0153</span>],</span><br><span class="line">        [<span class="number">0.9406</span>, <span class="number">0.0206</span>, <span class="number">0.0110</span>, <span class="number">0.0193</span>, <span class="number">0.0085</span>],</span><br><span class="line">        [<span class="number">0.9406</span>, <span class="number">0.0206</span>, <span class="number">0.0111</span>, <span class="number">0.0193</span>, <span class="number">0.0084</span>],</span><br><span class="line">        [<span class="number">0.9406</span>, <span class="number">0.0204</span>, <span class="number">0.0110</span>, <span class="number">0.0192</span>, <span class="number">0.0088</span>],</span><br><span class="line">        [<span class="number">0.9406</span>, <span class="number">0.0205</span>, <span class="number">0.0111</span>, <span class="number">0.0193</span>, <span class="number">0.0085</span>],</span><br><span class="line">        [<span class="number">0.9250</span>, <span class="number">0.0258</span>, <span class="number">0.0145</span>, <span class="number">0.0242</span>, <span class="number">0.0105</span>]], grad_fn=&lt;DivBackward1&gt;)</span><br><span class="line">        </span><br><span class="line">z[<span class="number">2</span>]</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">tensor([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>])</span><br></pre></td></tr></table></figure>

<p>看一下第二筆文件裡的字，估計主題效果還不錯</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">phi[<span class="number">0</span>]</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">tensor([<span class="number">1.1714e-03</span>, <span class="number">7.1110e-01</span>, <span class="number">1.4448e-03</span>, <span class="number">1.8015e-03</span>, <span class="number">1.0734e-01</span>, <span class="number">2.6613e-06</span>,</span><br><span class="line">        <span class="number">1.1921e-07</span>, <span class="number">3.6218e-03</span>, <span class="number">9.7121e-02</span>, <span class="number">1.1921e-07</span>, <span class="number">8.0717e-03</span>, <span class="number">7.9834e-07</span>,</span><br><span class="line">        <span class="number">6.8322e-02</span>, <span class="number">1.1921e-07</span>, <span class="number">1.1921e-07</span>])</span><br><span class="line"></span><br><span class="line">dist.Dirichlet(pyro.param(<span class="string">'beta_q'</span>)).sample()[<span class="number">0</span>]</span><br><span class="line">&gt;&gt;&gt;</span><br><span class="line">tensor([<span class="number">0.0089</span>, <span class="number">0.4932</span>, <span class="number">0.0083</span>, <span class="number">0.0549</span>, <span class="number">0.1486</span>, <span class="number">0.0355</span>, <span class="number">0.0272</span>, <span class="number">0.0291</span>, <span class="number">0.0509</span>,</span><br><span class="line">        <span class="number">0.0098</span>, <span class="number">0.0045</span>, <span class="number">0.0631</span>, <span class="number">0.0331</span>, <span class="number">0.0021</span>, <span class="number">0.0308</span>])</span><br></pre></td></tr></table></figure>

<p>來看第1個主題對應字的機率，都是第2個字的機率最高，代表主題1最相關的字為第2個，雖然分佈可能還有點差異，但效果也還不差</p>
<h2 id="結語"><a href="#結語" class="headerlink" title="結語"></a>結語</h2><p>深度學習結合機率方法是趨勢，這些PPL框架能更快投入研究與產品，後續會再分享一些Pyro應用與心得</p>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://odie2630463.github.io/2018/07/11/flow/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="odie">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="odie's whisper">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/07/11/flow/" itemprop="url">Normalizing Flows</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">發表於</span>
              
              <time title="創建於" itemprop="dateCreated datePublished" datetime="2018-07-11T15:13:46+08:00">2018-07-11</time>
            

            
            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分類於</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/flow/" itemprop="url" rel="index"><span itemprop="name">flow</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>機率分佈估計一直是機器學習中的核心問題，不論是分類問題估計條件機率分佈$p(y|x)$，或是建立生成模型$p(x,z)$，我們都在從資料中建立與學習出一個機率分佈</p>
<p>基本上機率分佈能做到兩件事：</p>
<ul>
<li>評估機率值，計算$p(x)$，給樣本空間的點都要能得出機率值</li>
<li>抽樣，計算$x \sim p(x)$，要能依機率密度來抽樣出樣本</li>
</ul>
<p>近年來，深度學習能有效率的近似高維度的複雜函數，而且還有完整的訓練框架，再加上機率圖模型概念，能表示很多複雜的機率分佈，但雖然能訓練模型來估計複雜分佈，也不一定能做到上面說的兩件事，比如：GAN很容易生成新影像，但卻無法給一張影像估計其機率值</p>
<p>Normalizing Flows是一種能將機率分佈轉換到另一個分佈的數學工具，例如把簡單的高斯分佈轉換至另一個複雜的機率分佈上，且依然能有效率評估機率值與抽樣，最近很多論文也開始結合這類的方法，例如：</p>
<ul>
<li><a href="https://arxiv.org/abs/1606.04934" target="_blank" rel="noopener">Improving Variational Inference with Inverse Autoregressive Flow</a></li>
<li><a href="https://arxiv.org/abs/1705.07057" target="_blank" rel="noopener">Masked Autoregressive Flow for Density Estimation</a></li>
</ul>
<p>還有最近由OpenAI剛發佈的<a href="https://arxiv.org/abs/1807.03039" target="_blank" rel="noopener">Glow: Generative Flow with Invertible 1x1 Convolutions</a>，基於Normalizing Flows的一種生成模型，也能生成高品質影像與表徵解構</p>
<h2 id="Normalizing-Flows"><a href="#Normalizing-Flows" class="headerlink" title="Normalizing Flows"></a>Normalizing Flows</h2><p>假設隨機變量$x \in \mathbb{R}^d$且$x \sim p(x)$，與一個可逆函數$f:\mathbb{R}^d \mapsto \mathbb{R}^d$，我們用$f$來轉換$p(x)$，可以得到另一個經過轉換的隨機變量$y=f(x)$與其機率分佈：</p>
<p>$<br>p(y) = p(x) \left|<br>    \mathrm{det} \frac{<br>      \partial f^{-1}<br>    }{<br>      \partial x<br>    }<br>  \right|<br>  = p(x) \left|<br>    \mathrm{det} \frac{<br>      \partial f<br>    }{<br>      \partial x<br>    }<br>  \right| ^{-1} \tag{1}<br>$</p>
<p>行列式直觀上是面積或是體積的<strong>縮放比例</strong>，機率為機率密度函數底下的面積，轉換函數$f$可是視為一種面積的縮放變形，所以$p(y)$由轉換前$p(x)$底下的面積，乘上行列式表示的面積縮放比例，因為是計算$f^{-1}$，這個面積縮放的比例係指$y$對於$x$影響，意思是說，給$y$來反推回去$x$，並調整$p(x)$底下的面積大小，但也可以計算向前過程的行列式來取倒數。</p>
<p>假設轉換由多個轉換函數$f_1 \dots f_K$組成，$z_k$為轉換過程的中間變量，最後得到的隨機變量$y = f_K \circ \dots\circ f_1(x)$，計算$\log p(y)$為：</p>
<p>$<br>\log p(y) = \log p(x) - \sum_{k=1}^K<br>  \log<br>    \left|<br>    \mathrm{det} \frac{<br>      \partial f_k<br>    }{<br>      \partial \mathbf{x}_{k-1}<br>    }<br>  \right| \tag{2}<br>$</p>
<p>綜上所述，NF有兩種計算，<strong>第一是向前抽樣計算</strong>，從$x$計算$y = f(x)$，<strong>第二是向後機率機算</strong>，給一個$y$要一步步往後做逆運算，計算轉換的行列式總和，最後求出$x$。</p>
<p>計算行列式最差時候需要<a href="https://en.wikipedia.org/wiki/Computational_complexity_of_mathematical_operations" target="_blank" rel="noopener">$O(n^3)$</a>，所以就需要設計比較容易計算行列式的轉換，例如 Masked Autoregressive Flow、Inversed Autoregressive Flow、RealNVP等等模型，有用到Autoregressive的特性，所以行列式會很容易計算，這些方法會在後續的文章中介紹。</p>
<h2 id="Training-and-sampling"><a href="#Training-and-sampling" class="headerlink" title="Training and sampling"></a>Training and sampling</h2><p><strong>向後機率計算</strong>，我們可以直接對$\log p(y)$最大化機率似然，給$y$透過一系列反函數得到$x$與行列式總和</p>
<p>$$x = f_1^{-1}  \circ \dots \circ f_K^{-1}(y)$$</p>
<p>最後計算$\log p(x)$減去轉換過程行列式總和(如式子2)，就可以算出$\log p(y)$，當然也就能用上SGD等優化方法，一系列轉換函數就當成一層層神經網路來訓練，只是這裡要求要能計算反函數</p>
<p><strong>向前抽樣計算</strong>，出新樣本很直觀，就從$p(x)$抽樣出$x$，經過轉換即可得到$y$，而且還能順便得到$p(y)$</p>
<p>$$y = f_K  \circ \dots \circ f_1(x)$$</p>
<hr>
<p>如果對NF有興趣，參考資料都很值得一看！</p>
<p>之後會放上一個實作例子，把簡單機率分佈轉換至一個複雜分佈，還有關於最近NF發展的論文的閱讀心得</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol>
<li><a href="https://blog.evjang.com/2018/01/nf1.html" target="_blank" rel="noopener">Normalizing Flows Tutorial by Eric Jang</a></li>
<li><a href="http://akosiorek.github.io/ml/2018/04/03/norm_flows.html" target="_blank" rel="noopener">Normalizing Flows by Adam Kosiorek</a></li>
<li><a href="https://www.slideshare.net/daynap1204/improving-variational-inference-with-inverse-autoregressive-flow-71213560" target="_blank" rel="noopener">Improving Variational Inference with Inverse Autoregressive Flow</a></li>
<li><a href="http://bjlkeng.github.io/posts/variational-autoencoders-with-inverse-autoregressive-flows/" target="_blank" rel="noopener">Variational Autoencoders with Inverse Autoregressive Flows</a></li>
</ol>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一頁"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">odie</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">12</span>
                    <span class="site-state-item-name">文章</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">5</span>
                    <span class="site-state-item-name">分類</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">5</span>
                    <span class="site-state-item-name">標籤</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          
          

          
          

          
            
          
          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate"> 
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">odie</span>

  

  
</div>




  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 強力驅動</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主題 &mdash; <a class="theme-link" target="_blank" href="https://github.com/theme-next/hexo-theme-next">NexT.Muse</a> v6.0.6</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.0.6"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.0.6"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.0.6"></script>



  



	





  





  










  





  

  

  

  
  

  
  
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  

  
    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

    
  


  
  

  

  

  

  

</body>
</html>
