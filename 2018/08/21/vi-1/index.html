<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zh-TW">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222">












<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />






















<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.0.6" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.0.6">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.0.6">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.0.6">


  <link rel="mask-icon" href="/images/logo.svg?v=6.0.6" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '6.0.6',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="Variational Inference 是一種近似複雜分佈的數學方法，我們假設一類計算簡單的候選分佈$q(z)$，並有另一個複雜難以計算的後驗分佈$p(z|x)$，我們希望從候選分佈中找一個最接近$p(z|x)$的$q^*(z)$，這個等同於最小化$KL(q(z) | p(z|x))$ 不過為什麼我們要近似後驗分佈$p(z|x)$呢？或是$q(z)$可以怎麼定義？與深度學習怎麼結合？本篇或接下">
<meta name="keywords" content="generative model,variational inference">
<meta property="og:type" content="article">
<meta property="og:title" content="漫談 Variational Inference (一)">
<meta property="og:url" content="https://odie2630463.github.io/2018/08/21/vi-1/index.html">
<meta property="og:site_name" content="odie&#39;s whisper">
<meta property="og:description" content="Variational Inference 是一種近似複雜分佈的數學方法，我們假設一類計算簡單的候選分佈$q(z)$，並有另一個複雜難以計算的後驗分佈$p(z|x)$，我們希望從候選分佈中找一個最接近$p(z|x)$的$q^*(z)$，這個等同於最小化$KL(q(z) | p(z|x))$ 不過為什麼我們要近似後驗分佈$p(z|x)$呢？或是$q(z)$可以怎麼定義？與深度學習怎麼結合？本篇或接下">
<meta property="og:locale" content="zh-TW">
<meta property="og:image" content="https://odie2630463.github.io/media/15342296556201.png">
<meta property="og:updated_time" content="2019-12-03T14:07:42.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="漫談 Variational Inference (一)">
<meta name="twitter:description" content="Variational Inference 是一種近似複雜分佈的數學方法，我們假設一類計算簡單的候選分佈$q(z)$，並有另一個複雜難以計算的後驗分佈$p(z|x)$，我們希望從候選分佈中找一個最接近$p(z|x)$的$q^*(z)$，這個等同於最小化$KL(q(z) | p(z|x))$ 不過為什麼我們要近似後驗分佈$p(z|x)$呢？或是$q(z)$可以怎麼定義？與深度學習怎麼結合？本篇或接下">
<meta name="twitter:image" content="https://odie2630463.github.io/media/15342296556201.png">






  <link rel="canonical" href="https://odie2630463.github.io/2018/08/21/vi-1/"/>



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>漫談 Variational Inference (一) | odie's whisper</title>
  









  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-TW">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"> 

<div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">odie's whisper</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切換導航欄">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        
          
  <li class="menu-item menu-item-home">
    <a href="/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-home"></i> <br />首頁</a>
</li>

      
        
        
          
  <li class="menu-item menu-item-about">
    <a href="/about/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-user"></i> <br />關於</a>
</li>

      
        
        
          
  <li class="menu-item menu-item-tags">
    <a href="/tags/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />標籤</a>
</li>

      
        
        
          
  <li class="menu-item menu-item-categories">
    <a href="/categories/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-th"></i> <br />分類</a>
</li>

      
        
        
          
  <li class="menu-item menu-item-archives">
    <a href="/archives/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />歸檔</a>
</li>

      

      
    </ul>
  

  
    

    
    
      
      
    
      
      
    
      
      
    
      
      
    
      
      
    
    

  


  

  
</nav>


  



 </div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://odie2630463.github.io/2018/08/21/vi-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="odie">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="odie's whisper">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">漫談 Variational Inference (一)</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">發表於</span>
              
              <time title="創建於" itemprop="dateCreated datePublished" datetime="2018-08-21T16:13:27+08:00">2018-08-21</time>
            

            
            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分類於</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/variational-inference/" itemprop="url" rel="index"><span itemprop="name">variational inference</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>Variational Inference 是一種近似複雜分佈的數學方法，我們假設一類計算簡單的<strong>候選分佈</strong>$q(z)$，並有另一個複雜難以計算的後驗分佈$p(z|x)$，我們希望從候選分佈中找一個最接近$p(z|x)$的$q^*(z)$，這個等同於最小化$KL(q(z) | p(z|x))$</p>
<p>不過為什麼我們要近似後驗分佈$p(z|x)$呢？或是$q(z)$可以怎麼定義？與深度學習怎麼結合？本篇或接下來的幾篇文章就來跟大家漫談一下VI，整理了自己看過有關的資料，從幾個角度切入推導，並來看看跟其他生成模型有什麼關係</p>
<h2 id="Latent-variable-model"><a href="#Latent-variable-model" class="headerlink" title="Latent variable model"></a>Latent variable model</h2><p>要談VI之前要先講一下隱變量模型(Latent variable model)，因為VI就是拿來求解隱變量模型方法之一，我們假設可觀測的隨機變數$x$與無法觀測的隱變量$z$聯合機率分佈為：</p>
<p>$$<br>p_{\theta}(x,z) = p_{\theta}(x|z)p(z)<br>$$</p>
<p>其中$p_{\theta}(x|z)$為一個參數化的模型來表示條件機率，再透過把$z$積分，我們可以得到$p(x)$：</p>
<p>$$<br>p_{\theta}(x) = \int p_{\theta}(x,z)dz<br>$$</p>
<p>看來很完美，我們得到$p(x)$式子接著就能直接去用MLE去學習 $\theta$ 囉！</p>
<p>這裡再多討論一下為何要使用隱變量模型，從上面式子來看，引入隱變量可以幫助我們定義出一個能計算的$p(x)$，解決了不知道怎麼假設$p(x)$的問題；另外，隱變量能捕捉資料所隱含的特性，例如「星座」是人們所加上的隱變量，有時候透過「星座」可以更快掌握你是個怎樣的人或是個性，或是說從你的行為來猜測你是什麼星座之類的，都是生活中常見的隱變量應用</p>
<p>不過更多時候，隱變量於表徵學習任務上扮演重要的角色，像是這個<a href="https://arxiv.org/abs/1704.03477" target="_blank" rel="noopener">手繪塗鴉</a>的例子，所學習到的隱變量於低維度可以形成<a href="https://zh.wikipedia.org/wiki/流形" target="_blank" rel="noopener">流型(Manifolds)</a>，隱變量能捕捉資料的變異性，形成一個漸變的空間且具有泛化能力，代表隱變量能更好的表示資料特性，是很好的表徵學習方法</p>
<p><img src="/media/15342296556201.png" alt="-w401"></p>
<h2 id="計算後驗機率困難"><a href="#計算後驗機率困難" class="headerlink" title="計算後驗機率困難"></a>計算後驗機率困難</h2><p>我們先來看看為什麼要近似$p(z|x)$，從隱變量模型，我們有一個可以計算的$p(x,z)$，現在把$p(x)$重新寫成：</p>
<p>$$<br>p(x) = \frac{p(x,z)}{p(z|x)}<br>$$</p>
<p>又是另一片天地，我們想要能計算$p(x)$，那只要$p(x,z)$與$p(z|x)$都可以被計算，那一切就太好了；只可惜，$p(z|x)$是無法被計算的，原因是：</p>
<p>$$<br>p(z|x) = \frac{p(x,z)}{p(x)}<br>$$</p>
<p>又導回來了，我們就是苦於沒有$p(x)$呀，那只好直接用另一個$q(z)$來偽裝成$p(z|x)$了，如果他們兩個夠相似，$p(x)$應該是可以被近似求出來的，這裡就用上VI想法了！</p>
<h2 id="Evidence-Lower-Bound"><a href="#Evidence-Lower-Bound" class="headerlink" title="Evidence Lower Bound"></a>Evidence Lower Bound</h2><p>我們希望用上$q_{\phi}(z)$來取代$p_{\theta}(z|x)$解決後驗計算困難問題，所以引入$q_{\phi}(z)$至$p(x)$得到：</p>
<p>$<br>\begin{split}<br>\log p_{\theta}(x) &amp;= \mathbb{E}_{q_{\phi}(z)} \left[ \log p_{\theta}(x) \right] \\<br>          &amp;= \mathbb{E}_{q_{\phi}(z)} \left[ \log \frac{p_{\theta}(x,z)}{p_{\theta}(z|x)} \right] \\<br>&amp;= \mathbb{E}_{q_{\phi}(z)}<br>          \left[<br>          \log \frac{p_{\theta}(x,z)}{q_{\phi}(z)} \frac{q_{\phi}(z)}{p_{\theta}(z|x)}<br>          \right] \\<br>&amp;= \mathbb{E}_{q_{\phi}(z)}<br>          \left[<br>          \log \frac{p_{\theta}(x,z)}{q_{\phi}(z)}\right] + \mathbb{E}_{q_{\phi}(z)} \left[ \log \frac{q_{\phi}(z)}{p_{\theta}(z|x)}<br>          \right] \\<br>&amp;= \mathbb{E}_{q_{\phi}(z)}<br>        \left[<br>          \log \frac{p_{\theta}(x,z)}             {q_{\phi}(z)}\right] + KL(q_{\phi}(z)|| p_{\theta}(z|x))<br>\end{split}$</p>
<p>我們將原本$\log_{\theta} p(x)$拆成兩項，先來看第二項，為我們VI方法裡面的候選分佈$q_{\phi}(z)$與後驗分佈$p_{\theta}(z|x)$的KL距離，一定大於等於0，但我們依然無法直接去最小化之間差距</p>
<p>所以轉看第一項，又因$\log p(x)$為一個定值，第一項就成為了一個下界(Lower Bound)並稱為Evidence Lower Bound(ELBO)，如果我們最大化第一項，不就等同於最小化第二項了嗎！而且第一項完全是可以算的！我們能透過訓練參數$\theta , \phi$來最大化ELBO，同時也減少$q_{\phi}(z)$與$p_{\theta}(z|x)$KL距離</p>
<p>最後整理成一般常看到ELBO形式</p>
<p>$$<br>\mathbb{E}_{q_{\phi}(z)}<br>        \left[<br>          \log \frac{p_{\theta}(x,z)}             {q_{\phi}(z)}\right] = \mathbb{E}\left[ \log p_{\theta}(x|z) \right] - KL(q_{\phi}(z) || p(z))<br>$$</p>
<h2 id="Importance-Sampling-to-ELBO"><a href="#Importance-Sampling-to-ELBO" class="headerlink" title="Importance Sampling to ELBO"></a>Importance Sampling to ELBO</h2><p>剛剛我們由計算後驗分佈困難而推導出了ELBO，這次我們從 Importance Sampling 出發來推出ELBO，計算$p_{\theta}(x)$是求解一個複雜的積分：<br>$$<br>p_{\theta}(x) = \int p_{\theta}(x|z)p(z)dz<br>$$</p>
<p>我們可以用 Importance Sampling 來近似這個積分，用一個簡單的$q_{\phi}(z)$來抽樣出$z$，並且根據$\frac{q_{\phi}(z)}{p(z)}$來決定抽樣出的樣本權重：</p>
<p>$<br>\begin{split}<br>p_{\theta}(x) &amp;= \int p_{\theta}(x|z) \frac{p(z)}{q_{\phi}(z)} q_{\phi}(z)dz \\<br>&amp;= \int p_{\theta}(x|z)w^{(s)}q_{\phi}(z)dz \quad w^{(s)} = \frac{p(z)}{q_{\phi}(z)} \\<br>&amp;\approx \frac{1}{S} \sum w^{(s)}p(x|z^{(s)})<br>\end{split}$</p>
<p>這裡用上<a href="https://zh.wikipedia.org/wiki/延森不等式" target="_blank" rel="noopener">Jensen’s inequality</a>：</p>
<p>$$<br>\log \int p(x)g(x) dx \ge \int p(x) \log g(x) dx<br>$$</p>
<p>代入得到：</p>
<p>$<br>\begin{split}<br>\log p_{\theta}(x) &amp;= log \int p_{\theta}(x|z) \frac{p(z)}{q_{\phi}(z)} q(z) dz \\<br>&amp;\ge \int q_{\phi}(z) \log \left[ p_{\theta}(x|z)\frac{p(z)}{q_{\phi}(z)}  \right] dz = \int q_{\phi}(z) \log_{\theta}(x|z) - \int q_{\phi}(z) \log \frac{q_{\phi}(z)}{p(z)} \\<br>\end{split}$</p>
<p>最後將式子整理成：</p>
<p>$$<br>\int q_{\phi}(z) \log_{\theta}(x|z) - \int q_{\phi}(z) \log \frac{q_{\phi}(z)}{p(z)} = \mathbb{E}\left[ \log p_{\theta}(x|z) \right] - KL(q_{\phi}(z) || p(z))<br>$$</p>
<h2 id="Variational-EM"><a href="#Variational-EM" class="headerlink" title="Variational EM"></a>Variational EM</h2><p>最後我們來給一個具體常用來求解隱變量模型的演算法，最大期望演算法(Expectation-Maximization Algorithm,EM)，這裡不打算從頭講起EM，但是這個演算法相當重要，值得深入了解，我推薦最近剛結束的<a href="http://deepbayes.ru/#materials" target="_blank" rel="noopener">DeepBayes課程</a>，裡面非常詳細介紹了EM方法，本小節也有參考課程資料</p>
<p>用EM求解高斯混和模型(Gaussian Mixed Model)時候，因為高斯分佈良好的性質，所以能很方便地得到公式解：</p>
<ul>
<li>E-step：$q(z) = p(z|x,\theta)$</li>
<li>Ｍ-step：$\max\limits_{\theta} \mathbb{E}\left[ \log p_{\theta}(x,z) - \log q(z) \right]$</li>
</ul>
<p>可以看到在E-step時候，$q(z)$總是有公式解，故我們是有一個最優的$q(z)$恰好等於$p(z|x)$，也就等於最小化$KL(q(z)|p(z|x))$為0，M-step訓練參數$\theta$來最大化$\log p_{\theta}(x)$，此時ELBO直接等於$\log p_{\theta}(x)$</p>
<p>但很多時候我們無法寫出E-step的公式解，所以我們就用上VI方法，並且假設候選分佈為一個簡單且每個分量皆為獨立的分佈$q(z)=\prod q(z_i)$，稱為Mean-Field Approximation，我們帶入回ELBO中可以得到</p>
<p>$<br>\begin{split}<br>ELBO(q, \theta) &amp; = \int \prod_i q_i(z_i) \Big[ \log p_{\theta}(x,z) - \sum_i \log q_i(z_i) \Big ]dz \\<br>&amp; = \int q_j(z_j) \Big [ \int \log p_{\theta}(x,z) \prod_{i \neq j} q_i(z_i)dz_i \Big ] dz_j - \int \sum_{i \neq j} \log q_i(z_i) \prod_{i \neq j} q_i(z_i)dz_i - \int q_i(z_i) \log q_i(z_i)dz_i \\<br>&amp; = \int q_j(z_j) \log \tilde p(x,z_j)dz_j - \int q_j(z_j) \log q_j(z_j) dz_j + const \\<br>&amp; = -KL(q_j(z_j) || \tilde p(x,z_j))<br>\end{split}<br>$</p>
<p>最後 Variational EM 我們可以寫成</p>
<ul>
<li>E-step：$q_j(z_j) \propto \tilde p(x,z_j)$</li>
<li>Ｍ-step：$\max\limits_{\theta} \mathbb{E}\left[ \log p_{\theta}(x,z) - \log q(z) \right]$</li>
</ul>
<p>計算$q_j(z_j) = \mathbb{E}_{i \neq j}\left[ \log p(x,z) \right]$，固定$z_j$然後將j以外的維度進行積分，白話一點就是固定一個維度，把其他維度的所有組合都試過一次來計算這個維度的機率分佈，涉及非常大量的計算，雖然Mean-Field Approximation一定能寫成這樣的解，但是很多時候依然無法計算</p>
<h2 id="結語"><a href="#結語" class="headerlink" title="結語"></a>結語</h2><p>本篇是漫談VI方法的第一篇，介紹了隱變量模型與其求解困難，並用上VI方法來求解模型，得出可以透過最大化ELBO來求解訓練參數，最後介紹了Variational EM方法與限制</p>
<p>第一篇算是基礎介紹，也是我論文裡文獻回顧又再回顧一次，介紹了兩種角度推導出ELBO，下一篇我打算來介紹與深度學習如何結合，突破Mean-Field Approximation限制，成為生成模型中一個重要的方法，敬請期待</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li>NIPS 2016 Tutorial，很完整介紹VI的發展歷史 <a href="https://media.nips.cc/Conferences/2016/Slides/6199-Slides.pdf" target="_blank" rel="noopener">Variational Inference: Foundations and Modern Methods</a></li>
<li>Shakir Mohamed 大神的教學投影片<a href="https://www.shakirm.com/papers/VITutorial.pdf" target="_blank" rel="noopener">Variational Inference for Machine Learning</a></li>
<li>VAE 提出者的博士論文，值得一看！<a href="https://www.dropbox.com/s/dl/v6ua3d9yt44vgb3/cover_and_thesis.pdf" target="_blank" rel="noopener">VARIATIONAL INFERENCE &amp; DEEP LEARNING: A NEW SYNTHESIS
</a></li>
<li><a href="https://chrischoy.github.io/research/Expectation-Maximization-and-Variational-Inference/" target="_blank" rel="noopener">Expectation Maximization and Variational Inference</a></li>
</ul>

      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/generative-model/" rel="tag"># generative model</a>
          
            <a href="/tags/variational-inference/" rel="tag"># variational inference</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/07/28/pyro-lda/" rel="next" title="LDA model use Pyro">
                <i class="fa fa-chevron-left"></i> LDA model use Pyro
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/09/09/transformer/" rel="prev" title="Attention Is All You Need">
                Attention Is All You Need <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目錄
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            本站概要
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">odie</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">14</span>
                    <span class="site-state-item-name">文章</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">7</span>
                    <span class="site-state-item-name">分類</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">6</span>
                    <span class="site-state-item-name">標籤</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          
          

          
          

          
            
          
          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Latent-variable-model"><span class="nav-number">1.</span> <span class="nav-text">Latent variable model</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#計算後驗機率困難"><span class="nav-number">2.</span> <span class="nav-text">計算後驗機率困難</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Evidence-Lower-Bound"><span class="nav-number">3.</span> <span class="nav-text">Evidence Lower Bound</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Importance-Sampling-to-ELBO"><span class="nav-number">4.</span> <span class="nav-text">Importance Sampling to ELBO</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Variational-EM"><span class="nav-number">5.</span> <span class="nav-text">Variational EM</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#結語"><span class="nav-number">6.</span> <span class="nav-text">結語</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Reference"><span class="nav-number">7.</span> <span class="nav-text">Reference</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love" id="animate"> 
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">odie</span>

  

  
</div>




  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 強力驅動</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主題 &mdash; <a class="theme-link" target="_blank" href="https://github.com/theme-next/hexo-theme-next">NexT.Muse</a> v6.0.6</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.0.6"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.0.6"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=6.0.6"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=6.0.6"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.0.6"></script>



  



	





  





  










  





  

  

  

  
  

  
  

  
    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

    
  


  
  

  

  

  

  

</body>
</html>
